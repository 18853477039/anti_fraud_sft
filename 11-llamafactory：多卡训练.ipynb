{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b0fec0-d7ea-47d2-a425-a6d2c69bbc61",
   "metadata": {},
   "source": [
    "## 引言\n",
    "[前文](https://golfxiao.blog.csdn.net/article/details/141440847)训练时都做了一定的编码工作，其实有一些框架可以支持我们零代码微调，[LLama-Factory](https://llamafactory.readthedocs.io/zh-cn/latest/)就是其中一个。这是一个专门针对大语言模型的微调和训练平台，有如下特性：\n",
    "- 支持常见的模型种类：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi 等等。 \n",
    "- 支持单GPU和多GPU训练。\n",
    "- 支持全参微调、Lora微调、QLora微调。\n",
    "……\n",
    "还有很多优秀的特性，详细参考：[https://llamafactory.readthedocs.io/zh-cn/latest/](https://llamafactory.readthedocs.io/zh-cn/latest/)\n",
    "\n",
    "本文会尝试用LLamaFactory进行一次多GPU训练。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf290e-9dcf-4782-8580-e9738a47f829",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "\n",
    "针对sft， llamafactory支持多种数据格式，我们这里选用alpaca，此格式简单清晰，每条数据只需包含三个字段：\n",
    "- instruction 列对应的内容为人类指令； \n",
    "- input 列对应的内容为人类输入；  \n",
    "- output 列对应的内容为模型回答。\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"instruction\": \"计算这些物品的总费用。 \",\n",
    "  \"input\": \"输入：汽车 - $3000，衣服 - $100，书 - $20。\",\n",
    "  \"output\": \"汽车、衣服和书的总费用为 $3000 + $100 + $20 = $3120。\"\n",
    "}\n",
    "```\n",
    "为了格式匹配，封装一个函数`to_alpaca`用于转换数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e7fb88-8b6b-4710-9769-53c7fbc9e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def to_alpaca(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:  \n",
    "        dataset = []\n",
    "        for line in infile:  \n",
    "            # 解析每一行的 JSON  \n",
    "            data = json.loads(line)  \n",
    "            response = {\"is_fraud\":data[\"label\"], \"fraud_speaker\":data[\"fraud_speaker\"], \"reason\":data[\"reason\"]}\n",
    "            item = {\n",
    "                'input': data['input'],\n",
    "                'output': json.dumps(response, ensure_ascii=False),\n",
    "                'instruction':data['instruction'],\n",
    "            }  \n",
    "            dataset.append(item)\n",
    "        # 将结果写入输出文件  \n",
    "        outfile.write(json.dumps(dataset, indent=4, ensure_ascii=False))  \n",
    "        print(f\"convert over，{input_path} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f7043-5878-47d8-9913-909a3e7a4173",
   "metadata": {},
   "source": [
    "批量将前一节构建好的数据作格式转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c789e42-1c7d-4337-b715-bb900dbd0b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert over，../dataset/train_test/train0902.jsonl to ../dataset/fraud/train_test/train0902_alpaca.jsonl\n",
      "convert over，../dataset/train_test/test0902.jsonl to ../dataset/fraud/train_test/test0902_alpaca.jsonl\n",
      "convert over，../dataset/train_test/eval0902.jsonl to ../dataset/fraud/train_test/eval0902_alpaca.jsonl\n"
     ]
    }
   ],
   "source": [
    "# 假设输入数据存储在 input.jsonl 文件中  \n",
    "input_files = [\n",
    "    '../dataset/train_test/train0902.jsonl',\n",
    "    '../dataset/train_test/test0902.jsonl',\n",
    "    '../dataset/train_test/eval0902.jsonl',\n",
    "]\n",
    "\n",
    "def filename(path):\n",
    "    filename_with_ext = os.path.basename(path)\n",
    "    filename, extention = os.path.splitext(filename_with_ext)\n",
    "    return filename\n",
    "\n",
    "for input_path in input_files:\n",
    "    output_path = f'../dataset/fraud/train_test/{filename(input_path)}_alpaca.jsonl'\n",
    "    to_alpaca(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58dec9-2c85-48e9-b2b1-2eaf285676e8",
   "metadata": {},
   "source": [
    "convert over，../dataset/fraud/train_test/train0819.jsonl to ../dataset/fraud/train_test/train0819_alpaca.json\n",
    "convert over，../dataset/fraud/train_test/test0819.jsonl to ../dataset/fraud/train_test/test0819_alpaca.json\n",
    "convert over，../dataset/fraud/train_test/eval0819.jsonl to ../dataset/fraud/train_test/eval0819_alpaca.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b1133-3d70-441e-8b73-cb26d0874e72",
   "metadata": {},
   "source": [
    "转换好数据集后，需要将其配置到LLamaFactory安装目录下的`data/dataset_info.json`文件中，只需要在文件最后添加我们新构造的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6486af-3447-4297-983c-c93aff8c3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"identity\": {\n",
    "    \"file_name\": \"identity.json\"\n",
    "  },\n",
    "  ……\n",
    "  \"anti_fraud\": {\n",
    "    \"file_name\": \"train0819_alpaca.jsonl\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9850eb9-743f-4a46-bd0b-19d877c3ae4a",
   "metadata": {},
   "source": [
    "## 参数配置\n",
    "LLamaFactory的训练参数采用yaml文件保存，在安装目录下的`examples`子目录下有各种微调方法的示例配置，可以直接拷贝一份进行修改。\n",
    "\n",
    "![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/95c191a523e840fc969c0d014c82047e.png)\n",
    "\n",
    "查看配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28bfe549-1b58-49e1-a36a-b67b4e251c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model\n",
      "model_name_or_path: /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\n",
      "resume_from_checkpoint: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0826/checkpoint-1200\n",
      "\n",
      "### method\n",
      "stage: sft\n",
      "do_train: true\n",
      "finetuning_type: lora\n",
      "lora_target: q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj\n",
      "lora_rank: 16\n",
      "lora_alpha: 32\n",
      "lora_dropout: 0.2\n",
      "\n",
      "\n",
      "### dataset\n",
      "dataset_dir: /data2/downloads/LLaMA-Factory/data\n",
      "dataset: anti_fraud\n",
      "template: qwen\n",
      "cutoff_len: 1024\n",
      "max_samples: 200000\n",
      "overwrite_cache: true\n",
      "preprocessing_num_workers: 16\n",
      "\n",
      "### output\n",
      "output_dir: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0826\n",
      "logging_steps: 10\n",
      "save_steps: 100\n",
      "plot_loss: true\n",
      "overwrite_output_dir: true\n",
      "\n",
      "### train\n",
      "per_device_train_batch_size: 16\n",
      "gradient_accumulation_steps: 1\n",
      "gradient_checkpointing: true\n",
      "learning_rate: 1.0e-4\n",
      "num_train_epochs: 10.0\n",
      "lr_scheduler_type: cosine\n",
      "warmup_ratio: 0.05\n",
      "bf16: true\n",
      "ddp_timeout: 180000000\n",
      "\n",
      "### eval\n",
      "val_size: 0.1\n",
      "per_device_eval_batch_size: 8\n",
      "eval_strategy: steps\n",
      "eval_steps: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cat /data2/downloads/LLaMA-Factory/qwen2_lora_sft.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9535ebc-0d33-41c8-8edc-2dc26313c2f1",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "设置环境变量CUDA_VISIBLE_DEVICES声明训练过程中允许使用4张显卡，显卡编号分别为1、2、3、4。\n",
    "\n",
    "使用\t`llamafactory-cli`命令启动训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b22ae5-c4dd-44c8-9130-f0bd87032421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b127ae5-742d-43f6-ab61-2160635cf233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-03-17 01:19:52] llamafactory.cli:143 >> Initializing 3 distributed tasks at: 127.0.0.1:29193\n",
      "[WARNING|2025-03-17 01:20:01] llamafactory.hparams.parser:148 >> `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "[INFO|2025-03-17 01:20:01] llamafactory.hparams.parser:383 >> Process rank: 0, world size: 3, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,027 >> loading file chat_template.jinja\n",
      "[INFO|2025-03-17 01:20:02] llamafactory.hparams.parser:383 >> Process rank: 1, world size: 3, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-03-17 01:20:02] llamafactory.hparams.parser:383 >> Process rank: 2, world size: 3, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2313] 2025-03-17 01:20:02,523 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:20:02,543 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:20:02,544 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-17 01:20:02,546 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2313] 2025-03-17 01:20:02,887 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-03-17 01:20:02] llamafactory.data.template:143 >> Add <|im_end|> to stop words.\n",
      "[rank1]:[W317 01:20:02.198831794 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[INFO|2025-03-17 01:20:02] llamafactory.data.loader:143 >> Loading dataset train0819_alpaca.jsonl...\n",
      "[rank2]:[W317 01:20:03.357903360 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "Converting format of dataset (num_proc=16): 100%|█| 21135/21135 [00:00<00:00, 54\n",
      "[rank0]:[W317 01:20:04.823255869 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 21135/21135 [00:03<00:00, 54\n",
      "training example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 271, 100431, 99639, 37474, 105051, 108704, 11, 220, 14880, 101042, 105051, 43815, 107189, 106037, 101052, 3837, 23031, 2236, 68805, 66017, 103929, 104317, 59151, 9623, 761, 97957, 25, 830, 91233, 8, 3407, 110395, 18, 25, 10236, 236, 108, 102865, 101393, 99487, 101314, 100006, 101189, 100006, 85336, 99360, 102683, 99225, 106630, 104528, 3837, 85336, 26939, 99487, 104671, 100634, 20412, 104917, 100634, 99557, 104366, 115203, 99487, 108398, 100634, 99650, 104468, 3837, 99650, 99725, 100662, 99792, 99692, 46944, 46944, 104160, 32757, 8997, 110395, 16, 25, 58230, 109, 20412, 151645, 198, 151644, 77091, 198, 4913, 285, 761, 97957, 788, 895, 92, 151645, 198]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true/false)。\n",
      "\n",
      "发言人3: 现在我所在这个哪里能够工艺能够去把屈光做得很好的，去到这个省级医院是自治区医院跟广西医科大学这个附属医院他们还可以，他们一直保持比较好的一个一个手术量。\n",
      "发言人1: 就是<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"is_fraud\": false}<|im_end|>\n",
      "\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4913, 285, 761, 97957, 788, 895, 92, 151645, 198]\n",
      "labels:\n",
      "{\"is_fraud\": false}<|im_end|>\n",
      "\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:20:09,346 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:20:09,347 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3979] 2025-03-17 01:20:09,402 >> loading weights file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/model.safetensors\n",
      "[INFO|modeling_utils.py:1633] 2025-03-17 01:20:14,576 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1140] 2025-03-17 01:20:14,586 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "[WARNING|logging.py:329] 2025-03-17 01:20:14,617 >> Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "[INFO|modeling_utils.py:4970] 2025-03-17 01:20:24,025 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4978] 2025-03-17 01:20:24,025 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1093] 2025-03-17 01:20:24,170 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:1140] 2025-03-17 01:20:24,171 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[INFO|2025-03-17 01:20:24] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-03-17 01:20:24] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-03-17 01:20:24] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-03-17 01:20:24] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
      "[INFO|2025-03-17 01:20:27] llamafactory.model.loader:143 >> trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n",
      "[INFO|trainer.py:746] 2025-03-17 01:20:27,339 >> Using auto half precision backend\n",
      "[WARNING|trainer.py:781] 2025-03-17 01:20:27,342 >> No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[WARNING|2025-03-17 01:20:27] llamafactory.train.callbacks:154 >> Previous trainer log in this folder will be deleted.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[INFO|trainer.py:2405] 2025-03-17 01:20:28,094 >> ***** Running training *****\n",
      "[INFO|trainer.py:2406] 2025-03-17 01:20:28,094 >>   Num examples = 19,021\n",
      "[INFO|trainer.py:2407] 2025-03-17 01:20:28,094 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2408] 2025-03-17 01:20:28,095 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:2411] 2025-03-17 01:20:28,095 >>   Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "[INFO|trainer.py:2412] 2025-03-17 01:20:28,095 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2413] 2025-03-17 01:20:28,095 >>   Total optimization steps = 3,970\n",
      "[INFO|trainer.py:2414] 2025-03-17 01:20:28,099 >>   Number of trainable parameters = 18,464,768\n",
      "{'loss': 0.0991, 'grad_norm': 1.3655898571014404, 'learning_rate': 5.025125628140704e-06, 'epoch': 0.03}\n",
      "{'loss': 0.0851, 'grad_norm': 0.8054947257041931, 'learning_rate': 1.0050251256281408e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0594, 'grad_norm': 0.4281049966812134, 'learning_rate': 1.507537688442211e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0405, 'grad_norm': 0.4228849411010742, 'learning_rate': 2.0100502512562815e-05, 'epoch': 0.1}\n",
      "{'loss': 0.033, 'grad_norm': 1.4056049585342407, 'learning_rate': 2.5125628140703518e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0339, 'grad_norm': 0.30130791664123535, 'learning_rate': 3.015075376884422e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0291, 'grad_norm': 0.27112749218940735, 'learning_rate': 3.517587939698493e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0301, 'grad_norm': 0.37303656339645386, 'learning_rate': 4.020100502512563e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0276, 'grad_norm': 0.6134911179542542, 'learning_rate': 4.522613065326633e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0261, 'grad_norm': 0.19121375679969788, 'learning_rate': 5.0251256281407036e-05, 'epoch': 0.25}\n",
      "  3%|▉                                     | 100/3970 [01:44<1:04:23,  1.00it/s][INFO|trainer.py:4258] 2025-03-17 01:22:12,802 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:22:12,803 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:22:12,803 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.06it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.14it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.47it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.34it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.33it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.91it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.47it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.15it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.03it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.12it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.05it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.31it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.78it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.42it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.19it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.83it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.72it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.16it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 74/89 [00:09<00:01,  8.22it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.76it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.74it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.76it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.72it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.94it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.07it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:01,  7.00it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.13it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.47it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.56it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.020586367696523666, 'eval_runtime': 12.0306, 'eval_samples_per_second': 175.718, 'eval_steps_per_second': 7.398, 'epoch': 0.25}\n",
      "  3%|▉                                     | 100/3970 [01:56<1:04:23,  1.00it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.80it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:22:24,858 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-100\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:22:24,932 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:22:24,934 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:22:25,789 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:22:25,794 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-100/special_tokens_map.json\n",
      "{'loss': 0.0214, 'grad_norm': 0.16719216108322144, 'learning_rate': 5.527638190954774e-05, 'epoch': 0.28}\n",
      "{'loss': 0.023, 'grad_norm': 0.1872265338897705, 'learning_rate': 6.030150753768844e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0254, 'grad_norm': 0.42953944206237793, 'learning_rate': 6.532663316582915e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0225, 'grad_norm': 0.21953044831752777, 'learning_rate': 7.035175879396985e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0252, 'grad_norm': 0.4025311768054962, 'learning_rate': 7.537688442211056e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0218, 'grad_norm': 0.24089273810386658, 'learning_rate': 8.040201005025126e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0236, 'grad_norm': 0.29847678542137146, 'learning_rate': 8.542713567839196e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0226, 'grad_norm': 0.1787736713886261, 'learning_rate': 9.045226130653267e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0204, 'grad_norm': 0.10351480543613434, 'learning_rate': 9.547738693467337e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0227, 'grad_norm': 0.1508992314338684, 'learning_rate': 9.999998264891393e-05, 'epoch': 0.5}\n",
      "  5%|██                                      | 200/3970 [03:38<59:03,  1.06it/s][INFO|trainer.py:4258] 2025-03-17 01:24:06,838 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:24:06,838 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:24:06,838 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.28it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.06it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.13it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.76it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.48it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.62it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.21it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.22it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  7.00it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.99it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.10it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.18it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.10it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.70it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.14it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.18it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.51it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.96it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.63it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.01717703603208065, 'eval_runtime': 12.0077, 'eval_samples_per_second': 176.053, 'eval_steps_per_second': 7.412, 'epoch': 0.5}\n",
      "  5%|██                                      | 200/3970 [03:50<59:03,  1.06it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:24:18,871 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-200\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:24:18,944 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:24:18,945 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:24:19,851 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:24:19,857 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-200/special_tokens_map.json\n",
      "{'loss': 0.0209, 'grad_norm': 0.10004452615976334, 'learning_rate': 9.99979005331567e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0186, 'grad_norm': 0.1933080106973648, 'learning_rate': 9.999234836576652e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0207, 'grad_norm': 0.1310146152973175, 'learning_rate': 9.998332653208571e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0204, 'grad_norm': 0.17047718167304993, 'learning_rate': 9.997083565826513e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0172, 'grad_norm': 0.21303124725818634, 'learning_rate': 9.995487661122073e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0197, 'grad_norm': 0.1253756731748581, 'learning_rate': 9.993545049857338e-05, 'epoch': 0.65}\n",
      "{'loss': 0.018, 'grad_norm': 0.23890945315361023, 'learning_rate': 9.991255866857194e-05, 'epoch': 0.68}\n",
      "{'loss': 0.017, 'grad_norm': 0.11748220771551132, 'learning_rate': 9.988620270999979e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0183, 'grad_norm': 0.26755788922309875, 'learning_rate': 9.985638445206446e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0196, 'grad_norm': 0.10483549535274506, 'learning_rate': 9.982310596427076e-05, 'epoch': 0.76}\n",
      "  8%|███                                     | 300/3970 [05:34<59:58,  1.02it/s][INFO|trainer.py:4258] 2025-03-17 01:26:03,040 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:26:03,040 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:26:03,040 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.29it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.05it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.42it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.30it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.00it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  7.99it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.69it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.45it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:09,  7.33it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.49it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.14it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.56it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.37it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.07it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.15it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.32it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.43it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.75it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.89it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.77it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.35it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.96it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.015862155705690384, 'eval_runtime': 11.9953, 'eval_samples_per_second': 176.236, 'eval_steps_per_second': 7.42, 'epoch': 0.76}\n",
      "  8%|███                                     | 300/3970 [05:46<59:58,  1.02it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:26:15,060 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-300\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:26:15,130 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:26:15,131 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:26:15,980 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:26:15,987 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-300/special_tokens_map.json\n",
      "{'loss': 0.0112, 'grad_norm': 0.07094259560108185, 'learning_rate': 9.978636955627706e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0192, 'grad_norm': 0.10563808679580688, 'learning_rate': 9.97461777777351e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0201, 'grad_norm': 0.13172242045402527, 'learning_rate': 9.970253341811292e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0222, 'grad_norm': 0.17777182161808014, 'learning_rate': 9.965543950650135e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0183, 'grad_norm': 0.24418778717517853, 'learning_rate': 9.960489931140372e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0174, 'grad_norm': 0.12288546562194824, 'learning_rate': 9.955091634050905e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0206, 'grad_norm': 0.17597055435180664, 'learning_rate': 9.949349434044861e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0175, 'grad_norm': 0.1117524579167366, 'learning_rate': 9.943263729653581e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0153, 'grad_norm': 0.1087448000907898, 'learning_rate': 9.93683494324897e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0236, 'grad_norm': 0.10507437586784363, 'learning_rate': 9.930063521014177e-05, 'epoch': 1.01}\n",
      " 10%|███▊                                  | 400/3970 [07:29<1:00:13,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 01:27:58,019 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:27:58,019 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:27:58,019 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.23it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.48it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.31it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.70it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.36it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.07it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.99it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.08it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  7.01it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.99it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.13it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.05it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.14it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.55it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.22it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.10it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.84it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.47it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.64it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:07<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.56it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.18it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.40it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.77it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.90it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.79it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.37it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.06it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.016174670308828354, 'eval_runtime': 11.9718, 'eval_samples_per_second': 176.582, 'eval_steps_per_second': 7.434, 'epoch': 1.01}\n",
      " 10%|███▊                                  | 400/3970 [07:41<1:00:13,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:28:10,058 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-400\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:28:10,164 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:28:10,167 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:28:11,036 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:28:11,050 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-400/special_tokens_map.json\n",
      "{'loss': 0.0199, 'grad_norm': 0.08750493824481964, 'learning_rate': 9.922949932912634e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0167, 'grad_norm': 0.10562152415513992, 'learning_rate': 9.91549467265543e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0176, 'grad_norm': 0.16793662309646606, 'learning_rate': 9.907698257667052e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0152, 'grad_norm': 0.061676621437072754, 'learning_rate': 9.899561229049472e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0166, 'grad_norm': 0.2936150133609772, 'learning_rate': 9.891084151544592e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0211, 'grad_norm': 0.0855461061000824, 'learning_rate': 9.882267613495049e-05, 'epoch': 1.16}\n",
      "{'loss': 0.018, 'grad_norm': 0.14435866475105286, 'learning_rate': 9.873112226803382e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0184, 'grad_norm': 0.14971590042114258, 'learning_rate': 9.863618626889561e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0188, 'grad_norm': 0.09134981036186218, 'learning_rate': 9.853787472646892e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0157, 'grad_norm': 0.22138254344463348, 'learning_rate': 9.84361944639628e-05, 'epoch': 1.26}\n",
      " 13%|█████                                   | 500/3970 [09:23<55:48,  1.04it/s][INFO|trainer.py:4258] 2025-03-17 01:29:52,299 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:29:52,299 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:29:52,299 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.29it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.06it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.34it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.02it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.48it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.31it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  7.00it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.60it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.54it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.18it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.15it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.61it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.50it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.30it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.30it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.70it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.015417348593473434, 'eval_runtime': 12.0089, 'eval_samples_per_second': 176.036, 'eval_steps_per_second': 7.411, 'epoch': 1.26}\n",
      " 13%|█████                                   | 500/3970 [09:35<55:48,  1.04it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:30:04,330 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-500\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:30:04,393 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:30:04,395 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:30:05,256 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:30:05,262 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 0.0159, 'grad_norm': 0.1970071643590927, 'learning_rate': 9.83311525383888e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0176, 'grad_norm': 0.14535090327262878, 'learning_rate': 9.822275624007113e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0167, 'grad_norm': 0.20696645975112915, 'learning_rate': 9.811101309214076e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0149, 'grad_norm': 0.10203209519386292, 'learning_rate': 9.799593085001314e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0162, 'grad_norm': 0.11069735139608383, 'learning_rate': 9.787751750085014e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0168, 'grad_norm': 0.15289580821990967, 'learning_rate': 9.775578126300552e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0184, 'grad_norm': 0.10750548541545868, 'learning_rate': 9.763073058545468e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0122, 'grad_norm': 0.09983428567647934, 'learning_rate': 9.75023741472082e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0197, 'grad_norm': 0.2612873315811157, 'learning_rate': 9.737072085670949e-05, 'epoch': 1.49}\n",
      "{'loss': 0.015, 'grad_norm': 0.1600344479084015, 'learning_rate': 9.723577985121656e-05, 'epoch': 1.51}\n",
      " 15%|██████                                  | 600/3970 [11:20<58:05,  1.03s/it][INFO|trainer.py:4258] 2025-03-17 01:31:48,986 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:31:48,986 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:31:48,986 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.44it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.27it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.00it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.01it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.32it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.55it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.36it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.22it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.56it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.37it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.30it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.81it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.16it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.98it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.48it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.014707769267261028, 'eval_runtime': 11.997, 'eval_samples_per_second': 176.21, 'eval_steps_per_second': 7.418, 'epoch': 1.51}\n",
      " 15%|██████                                  | 600/3970 [11:32<58:05,  1.03s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:32:01,031 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-600\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:32:01,097 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:32:01,099 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:32:01,982 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:32:02,002 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-600/special_tokens_map.json\n",
      "{'loss': 0.0148, 'grad_norm': 0.08979897946119308, 'learning_rate': 9.709756049616776e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0148, 'grad_norm': 0.06437962502241135, 'learning_rate': 9.695607238453188e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0124, 'grad_norm': 0.09917502850294113, 'learning_rate': 9.68113253361423e-05, 'epoch': 1.59}\n",
      "{'loss': 0.015, 'grad_norm': 0.16558927297592163, 'learning_rate': 9.66633293970155e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0169, 'grad_norm': 0.18140871822834015, 'learning_rate': 9.651209483865374e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0145, 'grad_norm': 0.20665276050567627, 'learning_rate': 9.635763215733229e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0124, 'grad_norm': 0.17300529778003693, 'learning_rate': 9.61999520733709e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0178, 'grad_norm': 0.07140558958053589, 'learning_rate': 9.603906553038971e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0169, 'grad_norm': 0.12340746074914932, 'learning_rate': 9.587498369454983e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0177, 'grad_norm': 0.11427871882915497, 'learning_rate': 9.570771795377828e-05, 'epoch': 1.76}\n",
      " 18%|███████                                 | 700/3970 [13:14<55:27,  1.02s/it][INFO|trainer.py:4258] 2025-03-17 01:33:43,346 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:33:43,347 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:33:43,347 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.31it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  8.94it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.41it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.29it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.01it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.00it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.32it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.41it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.38it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.19it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.06it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.41it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.55it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.32it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.49it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.55it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.20it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.42it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.35it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.96it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.014122387394309044, 'eval_runtime': 12.0031, 'eval_samples_per_second': 176.121, 'eval_steps_per_second': 7.415, 'epoch': 1.76}\n",
      " 18%|███████                                 | 700/3970 [13:27<55:27,  1.02s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:33:55,394 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-700\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:33:55,464 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:33:55,465 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:33:56,366 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:33:56,371 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-700/special_tokens_map.json\n",
      "{'loss': 0.0128, 'grad_norm': 0.07856523245573044, 'learning_rate': 9.553727991697763e-05, 'epoch': 1.79}\n",
      "{'loss': 0.0134, 'grad_norm': 0.1375991702079773, 'learning_rate': 9.536368141322033e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0238, 'grad_norm': 0.141631081700325, 'learning_rate': 9.518693449092772e-05, 'epoch': 1.84}\n",
      "{'loss': 0.0166, 'grad_norm': 0.1825152188539505, 'learning_rate': 9.500705141703383e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0147, 'grad_norm': 0.1391824632883072, 'learning_rate': 9.482404467613395e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0107, 'grad_norm': 0.13989172875881195, 'learning_rate': 9.463792696961819e-05, 'epoch': 1.91}\n",
      "{'loss': 0.015, 'grad_norm': 0.19936075806617737, 'learning_rate': 9.444871121479e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0156, 'grad_norm': 0.18996229767799377, 'learning_rate': 9.425641054396955e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0193, 'grad_norm': 0.18935897946357727, 'learning_rate': 9.406103830358237e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0124, 'grad_norm': 0.24125166237354279, 'learning_rate': 9.386260805323311e-05, 'epoch': 2.02}\n",
      " 20%|████████                                | 800/3970 [15:10<50:07,  1.05it/s][INFO|trainer.py:4258] 2025-03-17 01:35:38,642 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:35:38,642 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:35:38,642 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.06it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.42it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.30it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.57it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.32it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.41it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.38it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  7.00it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.38it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.55it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.33it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.02it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.91it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.92it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.18it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.10it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.63it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.18it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.88it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.35it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.72it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.06it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.99it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.013929376378655434, 'eval_runtime': 12.0037, 'eval_samples_per_second': 176.113, 'eval_steps_per_second': 7.414, 'epoch': 2.02}\n",
      " 20%|████████                                | 800/3970 [15:22<50:07,  1.05it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:35:50,729 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-800\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:35:50,781 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:35:50,782 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:35:51,650 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:35:51,655 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-800/special_tokens_map.json\n",
      "{'loss': 0.0092, 'grad_norm': 0.07572394609451294, 'learning_rate': 9.366113356476427e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0098, 'grad_norm': 0.2699849307537079, 'learning_rate': 9.345662882130057e-05, 'epoch': 2.07}\n",
      "{'loss': 0.0141, 'grad_norm': 0.10753848403692245, 'learning_rate': 9.324910801627835e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0121, 'grad_norm': 0.06898287683725357, 'learning_rate': 9.303858555246058e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0097, 'grad_norm': 0.12275940179824829, 'learning_rate': 9.28250760409371e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0111, 'grad_norm': 0.1142343059182167, 'learning_rate': 9.260859430011076e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0086, 'grad_norm': 0.23441265523433685, 'learning_rate': 9.238915535466877e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0112, 'grad_norm': 0.22666414082050323, 'learning_rate': 9.216677443454003e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0129, 'grad_norm': 0.32200106978416443, 'learning_rate': 9.194146697383814e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0124, 'grad_norm': 0.08213449269533157, 'learning_rate': 9.171324860979014e-05, 'epoch': 2.27}\n",
      " 23%|█████████                               | 900/3970 [17:08<52:10,  1.02s/it][INFO|trainer.py:4258] 2025-03-17 01:37:37,054 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:37:37,054 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:37:37,054 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.29it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.09it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.34it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.50it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.32it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.19it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.57it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.45it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.42it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.33it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.15it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.06it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.013630463741719723, 'eval_runtime': 11.9989, 'eval_samples_per_second': 176.183, 'eval_steps_per_second': 7.417, 'epoch': 2.27}\n",
      " 23%|█████████                               | 900/3970 [17:20<52:10,  1.02s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:37:49,077 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-900\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:37:49,149 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:37:49,150 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:37:50,059 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:37:50,064 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-900/special_tokens_map.json\n",
      "{'loss': 0.0141, 'grad_norm': 0.1821919083595276, 'learning_rate': 9.148213518165121e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0098, 'grad_norm': 0.10346221178770065, 'learning_rate': 9.124814272960547e-05, 'epoch': 2.32}\n",
      "{'loss': 0.011, 'grad_norm': 0.14418095350265503, 'learning_rate': 9.101128749365264e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0124, 'grad_norm': 0.09800158441066742, 'learning_rate': 9.077158591248089e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0119, 'grad_norm': 0.11709985882043839, 'learning_rate': 9.052905462232609e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0092, 'grad_norm': 0.21730023622512817, 'learning_rate': 9.028371045581696e-05, 'epoch': 2.42}\n",
      "{'loss': 0.0127, 'grad_norm': 0.1361532360315323, 'learning_rate': 9.003557044080706e-05, 'epoch': 2.44}\n",
      "{'loss': 0.013, 'grad_norm': 0.2834261655807495, 'learning_rate': 8.978465179919275e-05, 'epoch': 2.47}\n",
      "{'loss': 0.0099, 'grad_norm': 0.2083134651184082, 'learning_rate': 8.953097194571816e-05, 'epoch': 2.49}\n",
      "{'loss': 0.011, 'grad_norm': 0.08732795715332031, 'learning_rate': 8.927454848676633e-05, 'epoch': 2.52}\n",
      " 25%|█████████▊                             | 1000/3970 [19:03<50:27,  1.02s/it][INFO|trainer.py:4258] 2025-03-17 01:39:31,558 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:39:31,558 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:39:31,558 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.33it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.50it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.35it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.06it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.13it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.44it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.66it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.74it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.58it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.07it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.07it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.49it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.17it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.07it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.79it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.35it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.21it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.72it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.01319704856723547, 'eval_runtime': 12.0096, 'eval_samples_per_second': 176.026, 'eval_steps_per_second': 7.411, 'epoch': 2.52}\n",
      " 25%|█████████▊                             | 1000/3970 [19:15<50:27,  1.02s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:39:43,589 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1000\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:39:43,661 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:39:43,663 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:39:44,543 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:39:44,548 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 0.0107, 'grad_norm': 0.17498323321342468, 'learning_rate': 8.901539921913739e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0114, 'grad_norm': 0.17403121292591095, 'learning_rate': 8.875354212881337e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0102, 'grad_norm': 0.07800781726837158, 'learning_rate': 8.848899538970984e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0089, 'grad_norm': 0.12689407169818878, 'learning_rate': 8.822177736241463e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0113, 'grad_norm': 0.10808780044317245, 'learning_rate': 8.79519065929135e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0119, 'grad_norm': 0.14705617725849152, 'learning_rate': 8.767940181130303e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0081, 'grad_norm': 0.14256694912910461, 'learning_rate': 8.74042819304906e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0072, 'grad_norm': 0.3883892297744751, 'learning_rate': 8.712656604488179e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0118, 'grad_norm': 0.11033104360103607, 'learning_rate': 8.684627342905518e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0097, 'grad_norm': 0.11695703119039536, 'learning_rate': 8.65634235364246e-05, 'epoch': 2.77}\n",
      " 28%|██████████▊                            | 1100/3970 [20:58<50:08,  1.05s/it][INFO|trainer.py:4258] 2025-03-17 01:41:26,621 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:41:26,622 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:41:26,622 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.48it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.31it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.57it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.58it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.29it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.17it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.77it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.33it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.54it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.79it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.56it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.72it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:01,  7.00it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.96it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.13it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.47it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.91it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.013663152232766151, 'eval_runtime': 11.9997, 'eval_samples_per_second': 176.171, 'eval_steps_per_second': 7.417, 'epoch': 2.77}\n",
      " 28%|██████████▊                            | 1100/3970 [21:10<50:08,  1.05s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:41:38,644 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1100\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:41:38,712 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:41:38,714 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:41:39,560 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:41:39,566 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1100/special_tokens_map.json\n",
      "{'loss': 0.0079, 'grad_norm': 0.11675592511892319, 'learning_rate': 8.627803599788897e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0122, 'grad_norm': 0.08407505601644516, 'learning_rate': 8.599013062046985e-05, 'epoch': 2.82}\n",
      "{'loss': 0.0095, 'grad_norm': 0.16054922342300415, 'learning_rate': 8.569972738593678e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0107, 'grad_norm': 0.16635756194591522, 'learning_rate': 8.54068464494204e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0136, 'grad_norm': 0.11823485791683197, 'learning_rate': 8.51115081380137e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0112, 'grad_norm': 0.11715347319841385, 'learning_rate': 8.481373294936112e-05, 'epoch': 2.92}\n",
      "{'loss': 0.0098, 'grad_norm': 0.15520043671131134, 'learning_rate': 8.451354155023607e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0115, 'grad_norm': 0.17339274287223816, 'learning_rate': 8.421095477510646e-05, 'epoch': 2.97}\n",
      "{'loss': 0.012, 'grad_norm': 0.19379644095897675, 'learning_rate': 8.390599362468876e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0067, 'grad_norm': 0.08743401616811752, 'learning_rate': 8.359867926449045e-05, 'epoch': 3.02}\n",
      " 30%|███████████▊                           | 1200/3970 [22:54<48:13,  1.04s/it][INFO|trainer.py:4258] 2025-03-17 01:43:22,630 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:43:22,630 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:43:22,630 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.01it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.46it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.30it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.03it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.03it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.44it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.49it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.36it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.92it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.00it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.07it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.14it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.45it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.90it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.01187250204384327, 'eval_runtime': 12.0134, 'eval_samples_per_second': 175.971, 'eval_steps_per_second': 7.408, 'epoch': 3.02}\n",
      " 30%|███████████▊                           | 1200/3970 [23:06<48:13,  1.04s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.80it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:43:34,667 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1200\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:43:34,733 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:43:34,734 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:43:35,649 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:43:35,655 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1200/special_tokens_map.json\n",
      "{'loss': 0.0043, 'grad_norm': 0.08475586771965027, 'learning_rate': 8.328903302334108e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0038, 'grad_norm': 0.014793687500059605, 'learning_rate': 8.29770763919119e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0046, 'grad_norm': 0.12443837523460388, 'learning_rate': 8.266283102122438e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0059, 'grad_norm': 0.04927835613489151, 'learning_rate': 8.234631872114758e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0077, 'grad_norm': 0.14377601444721222, 'learning_rate': 8.202756145888431e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0047, 'grad_norm': 0.15011925995349884, 'learning_rate': 8.170658135744673e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0036, 'grad_norm': 0.07886869460344315, 'learning_rate': 8.13834006941207e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0038, 'grad_norm': 0.09670789539813995, 'learning_rate': 8.105804189891981e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0095, 'grad_norm': 0.1280970573425293, 'learning_rate': 8.073052755302864e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0056, 'grad_norm': 0.3316898047924042, 'learning_rate': 8.040088038723543e-05, 'epoch': 3.27}\n",
      " 33%|████████████▊                          | 1300/3970 [24:50<45:46,  1.03s/it][INFO|trainer.py:4258] 2025-03-17 01:45:18,859 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:45:18,859 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:45:18,859 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.06it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.06it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.69it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.33it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.26it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.08it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.98it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.99it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.15it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.96it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.07it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.02it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.19it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.52it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.97it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.01344360038638115, 'eval_runtime': 12.0054, 'eval_samples_per_second': 176.087, 'eval_steps_per_second': 7.413, 'epoch': 3.27}\n",
      " 33%|████████████▊                          | 1300/3970 [25:02<45:46,  1.03s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:45:30,889 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1300\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:45:30,951 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:45:30,952 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:45:31,864 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:45:31,869 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1300/special_tokens_map.json\n",
      "{'loss': 0.0052, 'grad_norm': 0.12721958756446838, 'learning_rate': 8.006912328035458e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0038, 'grad_norm': 0.03862572833895683, 'learning_rate': 7.97352792576387e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0055, 'grad_norm': 0.17539189755916595, 'learning_rate': 7.939937148918061e-05, 'epoch': 3.35}\n",
      "{'loss': 0.0037, 'grad_norm': 0.2359946221113205, 'learning_rate': 7.906142328830524e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0061, 'grad_norm': 0.19542622566223145, 'learning_rate': 7.872145810995158e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0077, 'grad_norm': 0.39798837900161743, 'learning_rate': 7.837949954904479e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0076, 'grad_norm': 0.10327108949422836, 'learning_rate': 7.803557133885868e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0049, 'grad_norm': 0.13052836060523987, 'learning_rate': 7.768969734936848e-05, 'epoch': 3.48}\n",
      "{'loss': 0.0034, 'grad_norm': 0.04414435848593712, 'learning_rate': 7.73419015855942e-05, 'epoch': 3.5}\n",
      "{'loss': 0.0031, 'grad_norm': 0.03314992040395737, 'learning_rate': 7.699220818593454e-05, 'epoch': 3.53}\n",
      " 35%|█████████████▊                         | 1400/3970 [26:46<42:34,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 01:47:14,413 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:47:14,413 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:47:14,413 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 10%|████▍                                       | 9/89 [00:01<00:09,  8.48it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:10,  7.84it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  7.99it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  7.97it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.61it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.40it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.24it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.62it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.40it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.37it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.22it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  7.00it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.27it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.26it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.14it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.76it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.85it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.16it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.90it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.99it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.92it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.08it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.14it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.020306987687945366, 'eval_runtime': 11.9987, 'eval_samples_per_second': 176.186, 'eval_steps_per_second': 7.417, 'epoch': 3.53}\n",
      " 35%|█████████████▊                         | 1400/3970 [26:58<42:34,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:47:26,472 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1400\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:47:26,535 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:47:26,536 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:47:27,486 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:47:27,491 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1400/special_tokens_map.json\n",
      "{'loss': 0.0032, 'grad_norm': 0.15050026774406433, 'learning_rate': 7.664064142049162e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0054, 'grad_norm': 0.21829570829868317, 'learning_rate': 7.628722568938658e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0051, 'grad_norm': 0.11114782840013504, 'learning_rate': 7.593198552106606e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0056, 'grad_norm': 0.1513577401638031, 'learning_rate': 7.55749455705998e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0061, 'grad_norm': 0.20075486600399017, 'learning_rate': 7.521613061796957e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0053, 'grad_norm': 0.08917080610990524, 'learning_rate': 7.48555655663493e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0057, 'grad_norm': 0.0629025399684906, 'learning_rate': 7.449327544037668e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0048, 'grad_norm': 0.20547036826610565, 'learning_rate': 7.412928538441634e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0043, 'grad_norm': 0.20079171657562256, 'learning_rate': 7.376362066081482e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0056, 'grad_norm': 0.024200377985835075, 'learning_rate': 7.339630664814716e-05, 'epoch': 3.78}\n",
      " 38%|██████████████▋                        | 1500/3970 [28:40<38:49,  1.06it/s][INFO|trainer.py:4258] 2025-03-17 01:49:09,323 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:49:09,323 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:49:09,323 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 15.97it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.02it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.42it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.29it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.02it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.03it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.49it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.63it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.47it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.50it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.21it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.48it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.46it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.48it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.19it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.93it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.48it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.25it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.72it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.45it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.40it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.51it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.29it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.02it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.92it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.02it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.70it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.84it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.15it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:10<00:01,  7.91it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.99it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.90it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.016548749059438705, 'eval_runtime': 12.0232, 'eval_samples_per_second': 175.826, 'eval_steps_per_second': 7.402, 'epoch': 3.78}\n",
      " 38%|██████████████▋                        | 1500/3970 [28:52<38:49,  1.06it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:49:21,370 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1500\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:49:21,435 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:49:21,436 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:49:22,312 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:49:22,316 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1500/special_tokens_map.json\n",
      "{'loss': 0.005, 'grad_norm': 0.25995033979415894, 'learning_rate': 7.30273688394556e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0052, 'grad_norm': 0.19860780239105225, 'learning_rate': 7.26568328404802e-05, 'epoch': 3.83}\n",
      "{'loss': 0.005, 'grad_norm': 0.17170818150043488, 'learning_rate': 7.228472436788176e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0043, 'grad_norm': 0.0671704113483429, 'learning_rate': 7.191106924745695e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0082, 'grad_norm': 0.13268868625164032, 'learning_rate': 7.15358934123459e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0084, 'grad_norm': 0.07581206411123276, 'learning_rate': 7.115922290123233e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0084, 'grad_norm': 0.24399012327194214, 'learning_rate': 7.07810838565364e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0054, 'grad_norm': 0.07687214761972427, 'learning_rate': 7.040150252260032e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0042, 'grad_norm': 0.06109991297125816, 'learning_rate': 7.002050524386675e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0019, 'grad_norm': 0.03895224258303642, 'learning_rate': 6.963811846305063e-05, 'epoch': 4.03}\n",
      " 40%|███████████████▋                       | 1600/3970 [30:35<39:47,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 01:51:03,988 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:51:03,988 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:51:03,988 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.31it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.34it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.48it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.19it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.27it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.45it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.42it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.99it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.13it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.05it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.10it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.04it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.31it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.80it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.18it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.77it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.13it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.06it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.63it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.016690189018845558, 'eval_runtime': 11.9983, 'eval_samples_per_second': 176.191, 'eval_steps_per_second': 7.418, 'epoch': 4.03}\n",
      " 40%|███████████████▋                       | 1600/3970 [30:47<39:47,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:51:16,009 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1600\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:51:16,072 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:51:16,073 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:51:16,950 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:51:16,955 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1600/special_tokens_map.json\n",
      "{'loss': 0.0026, 'grad_norm': 0.03891029953956604, 'learning_rate': 6.92543687193038e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0015, 'grad_norm': 0.002959319157525897, 'learning_rate': 6.886928264637306e-05, 'epoch': 4.08}\n",
      "{'loss': 0.002, 'grad_norm': 0.1154107078909874, 'learning_rate': 6.848288697075178e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0015, 'grad_norm': 0.03762732073664665, 'learning_rate': 6.809520850982489e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0013, 'grad_norm': 0.06499116122722626, 'learning_rate': 6.770627417000772e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0041, 'grad_norm': 0.24077188968658447, 'learning_rate': 6.731611094487855e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0028, 'grad_norm': 0.05277477949857712, 'learning_rate': 6.692474591330509e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0021, 'grad_norm': 0.14777719974517822, 'learning_rate': 6.653220623756521e-05, 'epoch': 4.23}\n",
      "{'loss': 0.002, 'grad_norm': 0.16731499135494232, 'learning_rate': 6.613851916146174e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0036, 'grad_norm': 0.02539709024131298, 'learning_rate': 6.57437120084316e-05, 'epoch': 4.28}\n",
      " 43%|████████████████▋                      | 1700/3970 [32:30<37:27,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 01:52:58,908 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:52:58,909 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:52:58,909 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.28it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.03it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.46it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.62it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.22it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.27it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.34it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.36it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.07it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.90it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.00it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.95it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.95it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.07it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.00it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.40it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.56it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.19it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.07it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.96it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.64it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████▌| 88/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.018017414957284927, 'eval_runtime': 12.0074, 'eval_samples_per_second': 176.058, 'eval_steps_per_second': 7.412, 'epoch': 4.28}\n",
      " 43%|████████████████▋                      | 1700/3970 [32:42<37:27,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  8.32it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:53:10,988 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1700\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:53:11,097 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:53:11,100 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:53:12,010 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:53:12,024 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1700/special_tokens_map.json\n",
      "{'loss': 0.0049, 'grad_norm': 0.8722843527793884, 'learning_rate': 6.534781217964943e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0052, 'grad_norm': 0.372593492269516, 'learning_rate': 6.495084715212598e-05, 'epoch': 4.33}\n",
      "{'loss': 0.003, 'grad_norm': 0.05548672378063202, 'learning_rate': 6.455284447680087e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0028, 'grad_norm': 0.07051344960927963, 'learning_rate': 6.415383177663068e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0022, 'grad_norm': 0.1208280622959137, 'learning_rate': 6.375383674467165e-05, 'epoch': 4.41}\n",
      "{'loss': 0.002, 'grad_norm': 0.019233135506510735, 'learning_rate': 6.335288714215772e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0017, 'grad_norm': 0.5630133152008057, 'learning_rate': 6.295101079657381e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0008, 'grad_norm': 0.06845274567604065, 'learning_rate': 6.254823559972449e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0026, 'grad_norm': 0.6839166879653931, 'learning_rate': 6.21445895057981e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0064, 'grad_norm': 0.32653433084487915, 'learning_rate': 6.17401005294267e-05, 'epoch': 4.53}\n",
      " 45%|█████████████████▋                     | 1800/3970 [34:25<35:23,  1.02it/s][INFO|trainer.py:4258] 2025-03-17 01:54:54,156 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:54:54,156 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:54:54,156 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.45it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.28it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.49it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.49it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.19it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.58it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.05it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.73it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.79it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.18it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.51it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.013327870517969131, 'eval_runtime': 12.0059, 'eval_samples_per_second': 176.081, 'eval_steps_per_second': 7.413, 'epoch': 4.53}\n",
      " 45%|█████████████████▋                     | 1800/3970 [34:37<35:23,  1.02it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:55:06,185 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1800\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:55:06,234 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:55:06,235 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:55:07,102 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:55:07,107 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1800/special_tokens_map.json\n",
      "{'loss': 0.0028, 'grad_norm': 0.09471340477466583, 'learning_rate': 6.133479674374176e-05, 'epoch': 4.56}\n",
      "{'loss': 0.002, 'grad_norm': 0.02875736728310585, 'learning_rate': 6.092870627842564e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0027, 'grad_norm': 0.3575616180896759, 'learning_rate': 6.052185731775945e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0014, 'grad_norm': 0.009235517121851444, 'learning_rate': 6.011427809866688e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0013, 'grad_norm': 0.020941782742738724, 'learning_rate': 5.9705996908754344e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0037, 'grad_norm': 0.0014554410008713603, 'learning_rate': 5.92970420843479e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0007, 'grad_norm': 0.1014978438615799, 'learning_rate': 5.888744200852645e-05, 'epoch': 4.71}\n",
      "{'loss': 0.0013, 'grad_norm': 0.2334499955177307, 'learning_rate': 5.8477225109151876e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0019, 'grad_norm': 0.05351679399609566, 'learning_rate': 5.806641985689611e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0032, 'grad_norm': 0.23858268558979034, 'learning_rate': 5.7655054763265045e-05, 'epoch': 4.79}\n",
      " 48%|██████████████████▋                    | 1900/3970 [36:21<32:31,  1.06it/s][INFO|trainer.py:4258] 2025-03-17 01:56:49,666 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:56:49,666 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:56:49,666 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.33it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.35it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.06it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.57it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.33it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.41it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.38it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.55it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.49it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.23it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.26it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.63it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.71it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.46it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.44it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.15it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.06it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.13it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.03it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.30it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.78it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.43it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.60it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.81it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.31it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.16it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.06it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.02it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.028402332216501236, 'eval_runtime': 12.0458, 'eval_samples_per_second': 175.497, 'eval_steps_per_second': 7.388, 'epoch': 4.79}\n",
      " 48%|██████████████████▋                    | 1900/3970 [36:33<32:31,  1.06it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:57:01,736 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1900\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:57:01,783 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:57:01,785 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:57:02,632 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:57:02,637 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1900/special_tokens_map.json\n",
      "{'loss': 0.0033, 'grad_norm': 0.0038608761969953775, 'learning_rate': 5.72431583786198e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0025, 'grad_norm': 0.10123403370380402, 'learning_rate': 5.683075929019515e-05, 'epoch': 4.84}\n",
      "{'loss': 0.0019, 'grad_norm': 0.5434656143188477, 'learning_rate': 5.641788612011555e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0025, 'grad_norm': 0.10917389392852783, 'learning_rate': 5.6004567523408545e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0033, 'grad_norm': 0.15726061165332794, 'learning_rate': 5.5590832186016096e-05, 'epoch': 4.91}\n",
      "{'loss': 0.0021, 'grad_norm': 0.013297182507812977, 'learning_rate': 5.5176708822803555e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0006, 'grad_norm': 0.04143242537975311, 'learning_rate': 5.476222617556684e-05, 'epoch': 4.96}\n",
      "{'loss': 0.0009, 'grad_norm': 0.06835168600082397, 'learning_rate': 5.4347413011037595e-05, 'epoch': 4.99}\n",
      "{'loss': 0.001, 'grad_norm': 0.06488454341888428, 'learning_rate': 5.3932298118886624e-05, 'epoch': 5.01}\n",
      "{'loss': 0.0005, 'grad_norm': 0.00879004504531622, 'learning_rate': 5.3516910309725874e-05, 'epoch': 5.04}\n",
      " 50%|███████████████████▋                   | 2000/3970 [38:17<32:31,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 01:58:45,763 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 01:58:45,764 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 01:58:45,764 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.04it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.06it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.13it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.49it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.31it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.24it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.38it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.71it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.59it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:07<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.40it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.75it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.96it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.02215471863746643, 'eval_runtime': 11.9972, 'eval_samples_per_second': 176.207, 'eval_steps_per_second': 7.418, 'epoch': 5.04}\n",
      " 50%|███████████████████▋                   | 2000/3970 [38:29<32:31,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.79it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 01:58:57,786 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2000\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 01:58:57,865 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 01:58:57,866 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 01:58:58,700 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 01:58:58,731 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2000/special_tokens_map.json\n",
      "{'loss': 0.0005, 'grad_norm': 0.03479669243097305, 'learning_rate': 5.310127841310881e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0004, 'grad_norm': 0.004436789080500603, 'learning_rate': 5.268543127552947e-05, 'epoch': 5.09}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0004920947831124067, 'learning_rate': 5.2269397758420524e-05, 'epoch': 5.11}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005927348509430885, 'learning_rate': 5.1853206736150104e-05, 'epoch': 5.14}\n",
      "{'loss': 0.0003, 'grad_norm': 0.6516361236572266, 'learning_rate': 5.1436887094017784e-05, 'epoch': 5.16}\n",
      "{'loss': 0.0, 'grad_norm': 0.00505771255120635, 'learning_rate': 5.102046772624992e-05, 'epoch': 5.19}\n",
      "{'loss': 0.0015, 'grad_norm': 0.015879882499575615, 'learning_rate': 5.0603977533994184e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0002, 'grad_norm': 0.020391251891851425, 'learning_rate': 5.0187445423313765e-05, 'epoch': 5.24}\n",
      "{'loss': 0.0007, 'grad_norm': 0.007180306129157543, 'learning_rate': 4.977090030318113e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0004, 'grad_norm': 0.19714629650115967, 'learning_rate': 4.935437108347169e-05, 'epoch': 5.29}\n",
      " 53%|████████████████████▋                  | 2100/3970 [40:13<32:23,  1.04s/it][INFO|trainer.py:4258] 2025-03-17 02:00:42,110 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:00:42,110 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:00:42,111 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.34it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.50it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.36it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.03it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.57it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.32it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.40it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  7.00it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.77it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.48it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.29it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.92it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.55it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.75it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.90it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.48it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.026063648983836174, 'eval_runtime': 11.9891, 'eval_samples_per_second': 176.326, 'eval_steps_per_second': 7.423, 'epoch': 5.29}\n",
      " 53%|████████████████████▋                  | 2100/3970 [40:25<32:23,  1.04s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:00:54,149 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2100\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:00:54,229 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:00:54,230 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:00:55,124 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:00:55,128 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2100/special_tokens_map.json\n",
      "{'loss': 0.002, 'grad_norm': 0.10560721158981323, 'learning_rate': 4.893788667295728e-05, 'epoch': 5.31}\n",
      "{'loss': 0.0022, 'grad_norm': 0.010476572439074516, 'learning_rate': 4.8521475977299816e-05, 'epoch': 5.34}\n",
      "{'loss': 0.0019, 'grad_norm': 0.009390580467879772, 'learning_rate': 4.810516789704507e-05, 'epoch': 5.37}\n",
      "{'loss': 0.0004, 'grad_norm': 0.000477185589261353, 'learning_rate': 4.7688991325616974e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0016318917041644454, 'learning_rate': 4.727297514731215e-05, 'epoch': 5.42}\n",
      "{'loss': 0.0021, 'grad_norm': 0.3035905361175537, 'learning_rate': 4.685714823529537e-05, 'epoch': 5.44}\n",
      "{'loss': 0.0012, 'grad_norm': 0.09738456457853317, 'learning_rate': 4.6441539449595526e-05, 'epoch': 5.47}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0057648783549666405, 'learning_rate': 4.602617763510272e-05, 'epoch': 5.49}\n",
      "{'loss': 0.002, 'grad_norm': 0.017709745094180107, 'learning_rate': 4.5611091619566244e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0015, 'grad_norm': 0.0046947430819272995, 'learning_rate': 4.51963102115939e-05, 'epoch': 5.54}\n",
      " 55%|█████████████████████▌                 | 2200/3970 [42:09<29:40,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 02:02:38,073 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:02:38,073 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:02:38,073 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.72it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.30it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.55it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.38it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.23it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  7.00it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.58it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.28it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.91it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.40it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.75it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.01834077574312687, 'eval_runtime': 11.9879, 'eval_samples_per_second': 176.344, 'eval_steps_per_second': 7.424, 'epoch': 5.54}\n",
      " 55%|█████████████████████▌                 | 2200/3970 [42:21<29:40,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:02:50,102 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2200\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:02:50,176 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:02:50,177 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:02:51,071 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:02:51,076 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2200/special_tokens_map.json\n",
      "{'loss': 0.001, 'grad_norm': 0.04784729331731796, 'learning_rate': 4.478186219865247e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0014, 'grad_norm': 0.012054272927343845, 'learning_rate': 4.436777634506986e-05, 'epoch': 5.59}\n",
      "{'loss': 0.0008, 'grad_norm': 0.021214917302131653, 'learning_rate': 4.3954081390038636e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.03144562616944313, 'learning_rate': 4.354080604562148e-05, 'epoch': 5.64}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0003376620006747544, 'learning_rate': 4.312797899475843e-05, 'epoch': 5.67}\n",
      "{'loss': 0.0018, 'grad_norm': 0.2448941022157669, 'learning_rate': 4.271562888927626e-05, 'epoch': 5.69}\n",
      "{'loss': 0.0008, 'grad_norm': 0.07040147483348846, 'learning_rate': 4.230378434789973e-05, 'epoch': 5.72}\n",
      "{'loss': 0.002, 'grad_norm': 0.013892732560634613, 'learning_rate': 4.1892473954265535e-05, 'epoch': 5.74}\n",
      "{'loss': 0.0003, 'grad_norm': 0.02354193478822708, 'learning_rate': 4.1481726254938395e-05, 'epoch': 5.77}\n",
      "{'loss': 0.0022, 'grad_norm': 0.246059387922287, 'learning_rate': 4.1071569757429794e-05, 'epoch': 5.79}\n",
      " 58%|██████████████████████▌                | 2300/3970 [44:05<26:51,  1.04it/s][INFO|trainer.py:4258] 2025-03-17 02:04:34,194 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:04:34,195 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:04:34,195 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.05it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.44it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.31it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.02it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.45it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.71it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.45it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.53it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.32it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.29it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.77it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.42it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.19it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.76it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.88it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.94it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.08it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.82it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.04it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:01,  7.00it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.14it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.47it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.92it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.020650368183851242, 'eval_runtime': 12.0241, 'eval_samples_per_second': 175.814, 'eval_steps_per_second': 7.402, 'epoch': 5.79}\n",
      " 58%|██████████████████████▌                | 2300/3970 [44:17<26:51,  1.04it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:04:46,287 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2300\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:04:46,371 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:04:46,372 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:04:47,291 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:04:47,296 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2300/special_tokens_map.json\n",
      "{'loss': 0.0009, 'grad_norm': 0.008219716139137745, 'learning_rate': 4.066203292821951e-05, 'epoch': 5.82}\n",
      "{'loss': 0.0008, 'grad_norm': 0.050168681889772415, 'learning_rate': 4.0253144190779904e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0005, 'grad_norm': 0.12834639847278595, 'learning_rate': 3.984493192360317e-05, 'epoch': 5.87}\n",
      "{'loss': 0.0016, 'grad_norm': 0.0017887784633785486, 'learning_rate': 3.943742445823182e-05, 'epoch': 5.89}\n",
      "{'loss': 0.0012, 'grad_norm': 0.013799597509205341, 'learning_rate': 3.903065007729234e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0011, 'grad_norm': 0.2412543147802353, 'learning_rate': 3.862463701253224e-05, 'epoch': 5.94}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0059828790836036205, 'learning_rate': 3.821941344286074e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0005, 'grad_norm': 0.019215311855077744, 'learning_rate': 3.781500749239292e-05, 'epoch': 5.99}\n",
      "{'loss': 0.0008, 'grad_norm': 0.1869576871395111, 'learning_rate': 3.74114472284979e-05, 'epoch': 6.02}\n",
      "{'loss': 0.0006, 'grad_norm': 0.17984706163406372, 'learning_rate': 3.700876065985077e-05, 'epoch': 6.05}\n",
      " 60%|███████████████████████▌               | 2400/3970 [45:59<25:04,  1.04it/s][INFO|trainer.py:4258] 2025-03-17 02:06:28,299 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:06:28,299 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:06:28,299 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.31it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.46it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.33it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.05it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.13it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.43it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.27it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.63it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.09it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.46it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.54it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.30it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.90it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.92it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.93it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.50it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.29it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.67it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.63it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.83it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.20it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.97it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.07it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.02it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.99it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.92it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.017483675852417946, 'eval_runtime': 12.0142, 'eval_samples_per_second': 175.958, 'eval_steps_per_second': 7.408, 'epoch': 6.05}\n",
      " 60%|███████████████████████▌               | 2400/3970 [46:11<25:04,  1.04it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:06:40,339 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2400\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:06:40,437 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:06:40,438 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:06:41,310 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:06:41,316 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2400/special_tokens_map.json\n",
      "{'loss': 0.0004, 'grad_norm': 0.060323867946863174, 'learning_rate': 3.660697573448879e-05, 'epoch': 6.07}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0050781057216227055, 'learning_rate': 3.620612033787154e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0002, 'grad_norm': 0.014508028514683247, 'learning_rate': 3.580622229094571e-05, 'epoch': 6.12}\n",
      "{'loss': 0.0004, 'grad_norm': 0.002953869756311178, 'learning_rate': 3.540730934821409e-05, 'epoch': 6.15}\n",
      "{'loss': 0.0002, 'grad_norm': 0.030120473355054855, 'learning_rate': 3.500940919580938e-05, 'epoch': 6.17}\n",
      "{'loss': 0.0006, 'grad_norm': 0.03620150685310364, 'learning_rate': 3.461254944957262e-05, 'epoch': 6.2}\n",
      "{'loss': 0.0011, 'grad_norm': 0.7912091016769409, 'learning_rate': 3.421675765313656e-05, 'epoch': 6.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.22719810903072357, 'learning_rate': 3.382206127601398e-05, 'epoch': 6.25}\n",
      "{'loss': 0.0012, 'grad_norm': 0.02127397619187832, 'learning_rate': 3.342848771169134e-05, 'epoch': 6.27}\n",
      "{'loss': 0.0001, 'grad_norm': 0.013712559826672077, 'learning_rate': 3.303606427572734e-05, 'epoch': 6.3}\n",
      " 63%|████████████████████████▌              | 2500/3970 [47:56<25:56,  1.06s/it][INFO|trainer.py:4258] 2025-03-17 02:08:24,538 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:08:24,539 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:08:24,539 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.31it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.35it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.08it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.38it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.54it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.66it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.74it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.05it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.48it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.17it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.07it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.13it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.06it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.32it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.55it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.72it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.16it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.93it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.019059311598539352, 'eval_runtime': 11.9986, 'eval_samples_per_second': 176.187, 'eval_steps_per_second': 7.418, 'epoch': 6.3}\n",
      " 63%|████████████████████████▌              | 2500/3970 [48:08<25:56,  1.06s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:08:36,585 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2500\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:08:36,639 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:08:36,639 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:08:37,525 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:08:37,530 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2500/special_tokens_map.json\n",
      "{'loss': 0.0003, 'grad_norm': 0.002908757422119379, 'learning_rate': 3.264481820385732e-05, 'epoch': 6.32}\n",
      "{'loss': 0.0004, 'grad_norm': 0.02167653664946556, 'learning_rate': 3.2254776650102845e-05, 'epoch': 6.35}\n",
      "{'loss': 0.001, 'grad_norm': 0.0027868617326021194, 'learning_rate': 3.186596668488722e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0004, 'grad_norm': 0.6402385830879211, 'learning_rate': 3.147841529315658e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0003, 'grad_norm': 0.003741523250937462, 'learning_rate': 3.109214937250718e-05, 'epoch': 6.42}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005704444483853877, 'learning_rate': 3.070719573131843e-05, 'epoch': 6.45}\n",
      "{'loss': 0.0005, 'grad_norm': 0.06141466274857521, 'learning_rate': 3.0323581086892418e-05, 'epoch': 6.47}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0029695588164031506, 'learning_rate': 2.9941332063599525e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0003, 'grad_norm': 0.14712689816951752, 'learning_rate': 2.9560475191030667e-05, 'epoch': 6.52}\n",
      "{'loss': 0.0, 'grad_norm': 0.000559064676053822, 'learning_rate': 2.918103690215599e-05, 'epoch': 6.55}\n",
      " 65%|█████████████████████████▌             | 2600/3970 [49:50<21:14,  1.07it/s][INFO|trainer.py:4258] 2025-03-17 02:10:18,810 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:10:18,810 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:10:18,810 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.05it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.36it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.20it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  7.96it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  7.99it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.41it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.38it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.12it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.92it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  7.00it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.13it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.10it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.84it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.47it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.64it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.18it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.50it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.51it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.28it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.15it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.92it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.08it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.90it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.08it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.44it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.90it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.022171074524521828, 'eval_runtime': 12.0309, 'eval_samples_per_second': 175.714, 'eval_steps_per_second': 7.398, 'epoch': 6.55}\n",
      " 65%|█████████████████████████▌             | 2600/3970 [50:02<21:14,  1.07it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:10:30,865 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2600\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:10:30,953 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:10:30,954 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:10:31,797 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:10:31,840 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2600/special_tokens_map.json\n",
      "{'loss': 0.0001, 'grad_norm': 0.0021754459012299776, 'learning_rate': 2.8803043531490365e-05, 'epoch': 6.57}\n",
      "{'loss': 0.0, 'grad_norm': 0.010613641701638699, 'learning_rate': 2.842652131326562e-05, 'epoch': 6.6}\n",
      "{'loss': 0.0, 'grad_norm': 7.293823728105053e-05, 'learning_rate': 2.8051496379609755e-05, 'epoch': 6.62}\n",
      "{'loss': 0.0, 'grad_norm': 0.0041000135242938995, 'learning_rate': 2.767799475873335e-05, 'epoch': 6.65}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00016536163457203656, 'learning_rate': 2.7306042373123103e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0012640287168323994, 'learning_rate': 2.693566503774256e-05, 'epoch': 6.7}\n",
      "{'loss': 0.0002, 'grad_norm': 0.023287346586585045, 'learning_rate': 2.656688845824069e-05, 'epoch': 6.73}\n",
      "{'loss': 0.0008, 'grad_norm': 0.0012129954993724823, 'learning_rate': 2.6199738229167627e-05, 'epoch': 6.75}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0074488441459834576, 'learning_rate': 2.5834239832198338e-05, 'epoch': 6.78}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00025747957988642156, 'learning_rate': 2.547041863436417e-05, 'epoch': 6.8}\n",
      " 68%|██████████████████████████▌            | 2700/3970 [51:46<21:34,  1.02s/it][INFO|trainer.py:4258] 2025-03-17 02:12:15,068 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:12:15,068 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:12:15,068 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.33it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.45it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.48it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.28it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.49it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.22it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.92it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.66it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.58it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.10it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.82it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.58it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.72it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.88it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.31it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.51it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.024006109684705734, 'eval_runtime': 12.0133, 'eval_samples_per_second': 175.971, 'eval_steps_per_second': 7.408, 'epoch': 6.8}\n",
      " 68%|██████████████████████████▌            | 2700/3970 [51:58<21:34,  1.02s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:12:27,134 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2700\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:12:27,207 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:12:27,208 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:12:28,134 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:12:28,140 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2700/special_tokens_map.json\n",
      "{'loss': 0.0008, 'grad_norm': 0.000380334589863196, 'learning_rate': 2.510829988629222e-05, 'epoch': 6.83}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0013410006649792194, 'learning_rate': 2.4747908720452807e-05, 'epoch': 6.85}\n",
      "{'loss': 0.0005, 'grad_norm': 0.02994704619050026, 'learning_rate': 2.4389270149415323e-05, 'epoch': 6.88}\n",
      "{'loss': 0.0017, 'grad_norm': 0.009019817225635052, 'learning_rate': 2.4032409064112054e-05, 'epoch': 6.9}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019669107859954238, 'learning_rate': 2.3677350232110827e-05, 'epoch': 6.93}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0007201640401035547, 'learning_rate': 2.3324118295895963e-05, 'epoch': 6.95}\n",
      "{'loss': 0.0006, 'grad_norm': 0.000661129248328507, 'learning_rate': 2.297273777115799e-05, 'epoch': 6.98}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019703574071172625, 'learning_rate': 2.2623233045092203e-05, 'epoch': 7.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0016341432929039001, 'learning_rate': 2.227562837470604e-05, 'epoch': 7.03}\n",
      "{'loss': 0.0004, 'grad_norm': 0.004709738306701183, 'learning_rate': 2.1929947885135566e-05, 'epoch': 7.05}\n",
      " 71%|███████████████████████████▌           | 2800/3970 [53:41<19:36,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 02:14:09,851 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:14:09,851 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:14:09,851 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.33it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.48it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.01it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.02it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.69it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.38it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.17it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.76it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.31it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.47it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.17it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.07it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.12it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.05it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.29it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.79it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.57it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.50it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.29it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.49it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.30it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.72it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.07it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.08it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.98it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.11it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.43it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.89it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.025005079805850983, 'eval_runtime': 12.021, 'eval_samples_per_second': 175.858, 'eval_steps_per_second': 7.404, 'epoch': 7.05}\n",
      " 71%|███████████████████████████▌           | 2800/3970 [53:53<19:36,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.78it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:14:21,903 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2800\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:14:21,971 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:14:21,972 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:14:22,840 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:14:22,845 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2800/special_tokens_map.json\n",
      "{'loss': 0.0001, 'grad_norm': 0.0001506140106357634, 'learning_rate': 2.158621556797112e-05, 'epoch': 7.08}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01873682625591755, 'learning_rate': 2.1244455279592196e-05, 'epoch': 7.1}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0006043995381332934, 'learning_rate': 2.090469073951169e-05, 'epoch': 7.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.002512881066650152, 'learning_rate': 2.0566945528729703e-05, 'epoch': 7.15}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00016878978931345046, 'learning_rate': 2.0231243088096913e-05, 'epoch': 7.18}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0005299432668834925, 'learning_rate': 1.9897606716687645e-05, 'epoch': 7.2}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0007104731048457325, 'learning_rate': 1.9566059570182922e-05, 'epoch': 7.23}\n",
      "{'loss': 0.001, 'grad_norm': 0.15813936293125153, 'learning_rate': 1.9236624659263304e-05, 'epoch': 7.25}\n",
      "{'loss': 0.0, 'grad_norm': 0.00010815593850566074, 'learning_rate': 1.89093248480118e-05, 'epoch': 7.28}\n",
      "{'loss': 0.0, 'grad_norm': 0.0016600429080426693, 'learning_rate': 1.8584182852327176e-05, 'epoch': 7.3}\n",
      " 73%|████████████████████████████▍          | 2900/3970 [55:36<18:18,  1.03s/it][INFO|trainer.py:4258] 2025-03-17 02:16:05,134 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:16:05,134 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:16:05,134 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.13it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.01it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.45it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.30it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.02it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.00it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.62it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.53it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.24it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.33it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.38it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.49it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.33it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.58it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.35it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.98it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.07it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  7.00it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.99it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.04it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.49it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.18it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.07it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.40it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.76it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.88it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.00it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.02it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.98it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.15it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.93it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.025758028030395508, 'eval_runtime': 12.005, 'eval_samples_per_second': 176.094, 'eval_steps_per_second': 7.414, 'epoch': 7.3}\n",
      " 73%|████████████████████████████▍          | 2900/3970 [55:48<18:18,  1.03s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:16:17,219 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2900\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:16:17,274 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:16:17,275 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:16:18,114 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:16:18,119 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2900/special_tokens_map.json\n",
      "{'loss': 0.0001, 'grad_norm': 0.00011160344001837075, 'learning_rate': 1.8261221238347233e-05, 'epoch': 7.33}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008367084083147347, 'learning_rate': 1.794046242088263e-05, 'epoch': 7.36}\n",
      "{'loss': 0.0004, 'grad_norm': 0.000452407548436895, 'learning_rate': 1.7621928661861324e-05, 'epoch': 7.38}\n",
      "{'loss': 0.0, 'grad_norm': 0.0018033295636996627, 'learning_rate': 1.7305642068783423e-05, 'epoch': 7.41}\n",
      "{'loss': 0.0, 'grad_norm': 0.0017462674295529723, 'learning_rate': 1.6991624593186782e-05, 'epoch': 7.43}\n",
      "{'loss': 0.0003, 'grad_norm': 8.897702355170622e-05, 'learning_rate': 1.6679898029123646e-05, 'epoch': 7.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.004682124592363834, 'learning_rate': 1.6370484011647914e-05, 'epoch': 7.48}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0001430234988220036, 'learning_rate': 1.6063404015313584e-05, 'epoch': 7.51}\n",
      "{'loss': 0.0001, 'grad_norm': 6.917024438735098e-05, 'learning_rate': 1.5758679352684426e-05, 'epoch': 7.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.00033964033355005085, 'learning_rate': 1.545633117285476e-05, 'epoch': 7.56}\n",
      " 76%|█████████████████████████████▍         | 3000/3970 [57:31<15:56,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 02:18:00,270 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:18:00,271 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:18:00,271 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  8.99it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.44it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.74it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.36it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.22it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.60it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.50it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.70it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.43it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.40it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.53it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.31it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.92it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.06it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.00it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.50it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.04it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.54it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.29it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.14it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.70it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.14it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:10<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.18it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.51it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.93it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.026056181639432907, 'eval_runtime': 12.0288, 'eval_samples_per_second': 175.745, 'eval_steps_per_second': 7.399, 'epoch': 7.56}\n",
      " 76%|█████████████████████████████▍         | 3000/3970 [57:43<15:56,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:18:12,362 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3000\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:18:12,461 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:18:12,463 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:18:13,365 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:18:13,381 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3000/special_tokens_map.json\n",
      "{'loss': 0.0, 'grad_norm': 9.664409299148247e-05, 'learning_rate': 1.5156380459981545e-05, 'epoch': 7.58}\n",
      "{'loss': 0.0003, 'grad_norm': 0.07836856693029404, 'learning_rate': 1.4858848031828182e-05, 'epoch': 7.61}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001535948133096099, 'learning_rate': 1.4563754538319508e-05, 'epoch': 7.63}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00022756280668545514, 'learning_rate': 1.4271120460108633e-05, 'epoch': 7.66}\n",
      "{'loss': 0.0005, 'grad_norm': 0.02430594339966774, 'learning_rate': 1.3980966107155608e-05, 'epoch': 7.68}\n",
      "{'loss': 0.0001, 'grad_norm': 0.02826245315372944, 'learning_rate': 1.3693311617317739e-05, 'epoch': 7.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.00011009073205059394, 'learning_rate': 1.3408176954951912e-05, 'epoch': 7.73}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0002972612273879349, 'learning_rate': 1.312558190952916e-05, 'epoch': 7.76}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0003939888847526163, 'learning_rate': 1.2845546094260952e-05, 'epoch': 7.78}\n",
      "{'loss': 0.0003, 'grad_norm': 7.390784594463184e-05, 'learning_rate': 1.2568088944738148e-05, 'epoch': 7.81}\n",
      " 78%|██████████████████████████████▍        | 3100/3970 [59:28<14:30,  1.00s/it][INFO|trainer.py:4258] 2025-03-17 02:19:56,798 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:19:56,798 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:19:56,798 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.32it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.05it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:10,  8.24it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:10,  8.16it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  7.92it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  7.95it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.05it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.03it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.67it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.50it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.50it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.20it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.48it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.35it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:09,  7.33it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.32it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.17it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.93it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.29it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.67it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.49it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.45it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.52it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.28it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.00it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.90it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.92it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  6.98it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.92it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.93it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.16it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  6.98it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.03it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.31it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.80it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.44it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.61it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.26it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.12it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.69it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.63it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.84it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.15it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:10<00:01,  7.91it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.99it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.99it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.97it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.13it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.48it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.93it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.026807142421603203, 'eval_runtime': 12.0526, 'eval_samples_per_second': 175.398, 'eval_steps_per_second': 7.384, 'epoch': 7.81}\n",
      " 78%|██████████████████████████████▍        | 3100/3970 [59:40<14:30,  1.00s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:20:08,874 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3100\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:20:08,937 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:20:08,938 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:20:09,748 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:20:09,753 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3100/special_tokens_map.json\n",
      "{'loss': 0.0007, 'grad_norm': 0.0008388342102989554, 'learning_rate': 1.2293229717582027e-05, 'epoch': 7.83}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0016926766838878393, 'learning_rate': 1.2020987489107805e-05, 'epoch': 7.86}\n",
      "{'loss': 0.0003, 'grad_norm': 0.001723372028209269, 'learning_rate': 1.1751381154000595e-05, 'epoch': 7.88}\n",
      "{'loss': 0.0006, 'grad_norm': 0.00014902331167832017, 'learning_rate': 1.1484429424004223e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00020424171816557646, 'learning_rate': 1.1220150826622333e-05, 'epoch': 7.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.00022227541194297373, 'learning_rate': 1.0958563703832675e-05, 'epoch': 7.96}\n",
      "{'loss': 0.0001, 'grad_norm': 0.030431192368268967, 'learning_rate': 1.0699686210814026e-05, 'epoch': 7.98}\n",
      "{'loss': 0.0002, 'grad_norm': 7.044721860438585e-05, 'learning_rate': 1.0443536314686153e-05, 'epoch': 8.01}\n",
      "{'loss': 0.0, 'grad_norm': 8.535152301192284e-05, 'learning_rate': 1.0190131793262853e-05, 'epoch': 8.04}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0005908976891078055, 'learning_rate': 9.939490233818083e-06, 'epoch': 8.06}\n",
      " 81%|█████████████████████████████▊       | 3200/3970 [1:01:24<12:45,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 02:21:52,553 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:21:52,553 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:21:52,553 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.26it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.01it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.44it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.30it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  7.99it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.01it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.07it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.28it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.34it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.13it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.36it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.54it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.48it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.41it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.93it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.00it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.16it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.07it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.14it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.04it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.31it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.80it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.41it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.72it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.33it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.94it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.94it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.08it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.03it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.49it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.93it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.026000579819083214, 'eval_runtime': 12.013, 'eval_samples_per_second': 175.976, 'eval_steps_per_second': 7.409, 'epoch': 8.06}\n",
      " 81%|█████████████████████████████▊       | 3200/3970 [1:01:36<12:45,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:22:04,590 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3200\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:22:04,655 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:22:04,656 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:22:05,535 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:22:05,539 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3200/special_tokens_map.json\n",
      "{'loss': 0.0002, 'grad_norm': 0.042195092886686325, 'learning_rate': 9.69162903186529e-06, 'epoch': 8.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.00011447828728705645, 'learning_rate': 9.446565389950185e-06, 'epoch': 8.11}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0001449033006792888, 'learning_rate': 9.204316316456769e-06, 'epoch': 8.14}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00018788641318678856, 'learning_rate': 8.964898624426826e-06, 'epoch': 8.16}\n",
      "{'loss': 0.0, 'grad_norm': 6.471773667726666e-05, 'learning_rate': 8.728328930393187e-06, 'epoch': 8.19}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002840475062839687, 'learning_rate': 8.49462365322632e-06, 'epoch': 8.21}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0206773541867733, 'learning_rate': 8.26379901299485e-06, 'epoch': 8.24}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0001665279851295054, 'learning_rate': 8.035871029839859e-06, 'epoch': 8.26}\n",
      "{'loss': 0.0001, 'grad_norm': 0.007419398054480553, 'learning_rate': 7.810855522862998e-06, 'epoch': 8.29}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0002571808290667832, 'learning_rate': 7.588768109028516e-06, 'epoch': 8.31}\n",
      " 83%|██████████████████████████████▊      | 3300/3970 [1:03:20<11:14,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 02:23:48,832 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:23:48,832 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:23:48,832 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.28it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.07it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.49it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.31it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.03it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.73it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.49it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.31it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.66it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.57it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.54it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.92it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.51it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.68it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.57it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.97it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.07it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.18it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.10it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.84it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.47it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.63it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:07<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.51it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.28it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.14it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.71it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.85it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.71it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.95it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.97it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.96it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.13it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.47it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.92it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.61it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████▌| 88/89 [00:11<00:00,  7.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.026921039447188377, 'eval_runtime': 11.9969, 'eval_samples_per_second': 176.212, 'eval_steps_per_second': 7.419, 'epoch': 8.31}\n",
      " 83%|██████████████████████████████▊      | 3300/3970 [1:03:32<11:14,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  8.34it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:24:00,850 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3300\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:24:00,913 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:24:00,914 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:24:01,759 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:24:01,764 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3300/special_tokens_map.json\n",
      "{'loss': 0.0001, 'grad_norm': 0.016728485003113747, 'learning_rate': 7.369624202079534e-06, 'epoch': 8.34}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006493637338280678, 'learning_rate': 7.153439011468116e-06, 'epoch': 8.36}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0004316650447435677, 'learning_rate': 6.940227541299738e-06, 'epoch': 8.39}\n",
      "{'loss': 0.0001, 'grad_norm': 6.10381830483675e-05, 'learning_rate': 6.730004589291961e-06, 'epoch': 8.41}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019158433133270591, 'learning_rate': 6.522784745747384e-06, 'epoch': 8.44}\n",
      "{'loss': 0.0, 'grad_norm': 0.00023713742848485708, 'learning_rate': 6.3185823925409945e-06, 'epoch': 8.46}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0003603854856919497, 'learning_rate': 6.1174117021221e-06, 'epoch': 8.49}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007168641313910484, 'learning_rate': 5.919286636530613e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0001, 'grad_norm': 8.815159526420757e-05, 'learning_rate': 5.7242209464280385e-06, 'epoch': 8.54}\n",
      "{'loss': 0.0002, 'grad_norm': 0.06857145577669144, 'learning_rate': 5.532228170143183e-06, 'epoch': 8.56}\n",
      " 86%|███████████████████████████████▋     | 3400/3970 [1:05:15<09:26,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 02:25:44,207 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:25:44,207 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:25:44,207 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.18it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.03it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.42it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.27it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.00it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.01it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.64it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.24it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.49it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.39it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.47it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.31it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.60it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.69it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.44it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.41it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.96it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.99it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.06it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.98it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.03it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.12it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.60it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.16it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.67it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.87it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.32it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.17it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.02it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.19it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.52it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.97it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.027882002294063568, 'eval_runtime': 12.0004, 'eval_samples_per_second': 176.161, 'eval_steps_per_second': 7.416, 'epoch': 8.56}\n",
      " 86%|███████████████████████████████▋     | 3400/3970 [1:05:27<09:26,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:25:56,232 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3400\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:25:56,317 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:25:56,318 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:25:57,210 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:25:57,215 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3400/special_tokens_map.json\n",
      "{'loss': 0.0003, 'grad_norm': 0.0004965323605574667, 'learning_rate': 5.343321632732506e-06, 'epoch': 8.59}\n",
      "{'loss': 0.0, 'grad_norm': 4.0581471694167703e-05, 'learning_rate': 5.157514445055267e-06, 'epoch': 8.61}\n",
      "{'loss': 0.0, 'grad_norm': 0.0017394529422745109, 'learning_rate': 4.9748195028636865e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001538676006020978, 'learning_rate': 4.795249485907799e-06, 'epoch': 8.66}\n",
      "{'loss': 0.0, 'grad_norm': 0.00020489597227424383, 'learning_rate': 4.618816857055536e-06, 'epoch': 8.69}\n",
      "{'loss': 0.0005, 'grad_norm': 5.9629674069583416e-05, 'learning_rate': 4.445533861427697e-06, 'epoch': 8.72}\n",
      "{'loss': 0.0, 'grad_norm': 0.004127904772758484, 'learning_rate': 4.275412525548123e-06, 'epoch': 8.74}\n",
      "{'loss': 0.0011, 'grad_norm': 0.0002542795264162123, 'learning_rate': 4.108464656508937e-06, 'epoch': 8.77}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0019855659920722246, 'learning_rate': 3.9447018411512105e-06, 'epoch': 8.79}\n",
      "{'loss': 0.0005, 'grad_norm': 9.683104872237891e-05, 'learning_rate': 3.784135445260656e-06, 'epoch': 8.82}\n",
      " 88%|████████████████████████████████▌    | 3500/3970 [1:07:11<07:53,  1.01s/it][INFO|trainer.py:4258] 2025-03-17 02:27:39,719 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:27:39,720 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:27:39,720 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.29it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.46it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.31it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.02it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.03it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.10it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.06it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.37it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.47it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.33it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.20it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.97it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.45it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.26it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.64it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.46it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.33it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.91it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.02it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.95it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.94it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.00it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.50it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.05it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.02it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.26it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.76it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.41it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.56it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.30it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.15it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.70it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.65it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.85it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.70it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:10<00:01,  7.89it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.94it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.01it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.96it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.027480557560920715, 'eval_runtime': 12.0328, 'eval_samples_per_second': 175.686, 'eval_steps_per_second': 7.396, 'epoch': 8.82}\n",
      " 88%|████████████████████████████████▌    | 3500/3970 [1:07:23<07:53,  1.01s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.72it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:27:51,778 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3500\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:27:51,849 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:27:51,850 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:27:52,702 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:27:52,707 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3500/special_tokens_map.json\n",
      "{'loss': 0.0009, 'grad_norm': 9.63678103289567e-05, 'learning_rate': 3.626776612778904e-06, 'epoch': 8.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.001386636053211987, 'learning_rate': 3.472636265030005e-06, 'epoch': 8.87}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0001126492497860454, 'learning_rate': 3.321725099962447e-06, 'epoch': 8.89}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00011340124910930172, 'learning_rate': 3.1740535914067225e-06, 'epoch': 8.92}\n",
      "{'loss': 0.0003, 'grad_norm': 6.260450754780322e-05, 'learning_rate': 3.0296319883483916e-06, 'epoch': 8.94}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003492319956421852, 'learning_rate': 2.8884703142166956e-06, 'epoch': 8.97}\n",
      "{'loss': 0.0, 'grad_norm': 7.764897600281984e-05, 'learning_rate': 2.7505783661889773e-06, 'epoch': 8.99}\n",
      "{'loss': 0.0, 'grad_norm': 0.00012191174027975649, 'learning_rate': 2.6159657145106765e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00033613204141147435, 'learning_rate': 2.484641701831103e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0008819090435281396, 'learning_rate': 2.3566154425550767e-06, 'epoch': 9.07}\n",
      " 91%|█████████████████████████████████▌   | 3600/3970 [1:09:06<06:11,  1.00s/it][INFO|trainer.py:4258] 2025-03-17 02:29:35,171 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:29:35,171 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:29:35,171 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.28it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.06it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.47it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.03it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.68it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.46it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.29it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.25it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.30it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.38it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.36it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.51it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.94it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.52it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.70it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.75it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.44it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.54it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.32it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.03it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.02it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.85it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.47it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.63it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.57it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.89it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.26it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.10it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.64it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.91it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.00it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.10it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.12it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.05it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.95it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.02733997069299221, 'eval_runtime': 12.0024, 'eval_samples_per_second': 176.131, 'eval_steps_per_second': 7.415, 'epoch': 9.07}\n",
      " 91%|█████████████████████████████████▌   | 3600/3970 [1:09:18<06:11,  1.00s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:29:47,198 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3600\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:29:47,264 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:29:47,265 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:29:48,152 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:29:48,157 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3600/special_tokens_map.json\n",
      "{'loss': 0.0003, 'grad_norm': 0.0001988407166209072, 'learning_rate': 2.2318958222103006e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0004, 'grad_norm': 0.023990808054804802, 'learning_rate': 2.1104914968306577e-06, 'epoch': 9.12}\n",
      "{'loss': 0.0, 'grad_norm': 0.000176441521034576, 'learning_rate': 1.9924108923555174e-06, 'epoch': 9.14}\n",
      "{'loss': 0.0004, 'grad_norm': 5.131580837769434e-05, 'learning_rate': 1.8776622040448777e-06, 'epoch': 9.17}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0005495575023815036, 'learning_rate': 1.7662533959105888e-06, 'epoch': 9.19}\n",
      "{'loss': 0.0, 'grad_norm': 0.00010619756358209997, 'learning_rate': 1.6581922001636774e-06, 'epoch': 9.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0008492569904774427, 'learning_rate': 1.553486116677627e-06, 'epoch': 9.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.00013549368304666132, 'learning_rate': 1.4521424124678884e-06, 'epoch': 9.27}\n",
      "{'loss': 0.0001, 'grad_norm': 7.994311454240233e-05, 'learning_rate': 1.3541681211875324e-06, 'epoch': 9.29}\n",
      "{'loss': 0.0001, 'grad_norm': 5.4141160944709554e-05, 'learning_rate': 1.2595700426390632e-06, 'epoch': 9.32}\n",
      " 93%|██████████████████████████████████▍  | 3700/3970 [1:11:01<04:31,  1.00s/it][INFO|trainer.py:4258] 2025-03-17 02:31:30,164 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:31:30,164 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:31:30,164 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.30it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.08it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.50it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.32it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.70it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.23it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.60it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.24it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.40it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.37it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.45it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.30it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.18it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.93it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.10it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.50it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.32it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.28it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.30it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.46it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.33it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.91it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.02it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.08it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.50it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.19it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.08it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.15it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.07it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.33it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.77it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.42it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.52it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.32it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.48it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.31it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.29it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.14it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.27it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.65it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.61it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.76it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.13it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.66it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:10<00:01,  7.91it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.00it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.95it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.80it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.02it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.98it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.09it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.44it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.90it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.027692899107933044, 'eval_runtime': 12.0326, 'eval_samples_per_second': 175.69, 'eval_steps_per_second': 7.397, 'epoch': 9.32}\n",
      " 93%|██████████████████████████████████▍  | 3700/3970 [1:11:13<04:31,  1.00s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:12<00:00,  7.77it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:31:42,297 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3700\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:31:42,368 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:31:42,368 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:31:43,252 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:31:43,257 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3700/special_tokens_map.json\n",
      "{'loss': 0.0004, 'grad_norm': 0.00013733706146012992, 'learning_rate': 1.168354742302491e-06, 'epoch': 9.35}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00022981753863859922, 'learning_rate': 1.0805285508796891e-06, 'epoch': 9.37}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0603405199944973, 'learning_rate': 9.960975638549807e-07, 'epoch': 9.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.00011351581633789465, 'learning_rate': 9.150676410720981e-07, 'epoch': 9.42}\n",
      "{'loss': 0.0, 'grad_norm': 4.108534267288633e-05, 'learning_rate': 8.374444063275033e-07, 'epoch': 9.45}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006206462276168168, 'learning_rate': 7.632332469800552e-07, 'epoch': 9.47}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0009673662134446204, 'learning_rate': 6.924393135771146e-07, 'epoch': 9.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001837236195569858, 'learning_rate': 6.250675194970801e-07, 'epoch': 9.52}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005079436232335865, 'learning_rate': 5.611225406083609e-07, 'epoch': 9.55}\n",
      "{'loss': 0.0, 'grad_norm': 0.002510677557438612, 'learning_rate': 5.006088149448862e-07, 'epoch': 9.57}\n",
      " 96%|███████████████████████████████████▍ | 3800/3970 [1:12:57<02:48,  1.01it/s][INFO|trainer.py:4258] 2025-03-17 02:33:25,863 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:33:25,863 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:33:25,863 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.29it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.04it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.45it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.31it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.03it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.04it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.12it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.09it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.69it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.45it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.28it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.65it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.55it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.56it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.26it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.41it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:08,  7.38it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.52it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.53it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.35it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.98it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.95it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.33it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.71it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.74it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.47it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.43it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.49it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.29it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.91it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.93it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.96it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.11it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.53it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.21it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.10it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.17it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.09it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.35it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.81it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.45it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.62it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.53it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.39it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.74it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.68it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.75it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.34it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.63it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.88it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  6.98it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.94it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.09it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.82it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.00it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.04it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.17it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.51it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.94it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.027710799127817154, 'eval_runtime': 12.0132, 'eval_samples_per_second': 175.973, 'eval_steps_per_second': 7.409, 'epoch': 9.57}\n",
      " 96%|███████████████████████████████████▍ | 3800/3970 [1:13:09<02:48,  1.01it/s]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:33:37,948 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3800\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:33:38,017 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:33:38,018 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:33:38,999 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:33:39,004 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3800/special_tokens_map.json\n",
      "{'loss': 0.0, 'grad_norm': 0.008279555477201939, 'learning_rate': 4.4353054239804625e-07, 'epoch': 9.6}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0005617006099782884, 'learning_rate': 3.8989168442524757e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0021000441629439592, 'learning_rate': 3.3969596377493305e-07, 'epoch': 9.65}\n",
      "{'loss': 0.0004, 'grad_norm': 0.03675249218940735, 'learning_rate': 2.929468642282329e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001534028328023851, 'learning_rate': 2.496476303571749e-07, 'epoch': 9.7}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0006857662810944021, 'learning_rate': 2.0980126729948092e-07, 'epoch': 9.72}\n",
      "{'loss': 0.0, 'grad_norm': 1.9399858501856215e-05, 'learning_rate': 1.734105405500175e-07, 'epoch': 9.75}\n",
      "{'loss': 0.0, 'grad_norm': 8.425144187640399e-05, 'learning_rate': 1.4047797576885457e-07, 'epoch': 9.77}\n",
      "{'loss': 0.0002, 'grad_norm': 7.386018114630133e-05, 'learning_rate': 1.1100585860596146e-07, 'epoch': 9.8}\n",
      "{'loss': 0.0, 'grad_norm': 0.00048195821000263095, 'learning_rate': 8.499623454260031e-08, 'epoch': 9.82}\n",
      " 98%|████████████████████████████████████▎| 3900/3970 [1:14:52<01:12,  1.03s/it][INFO|trainer.py:4258] 2025-03-17 02:35:20,872 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:35:20,872 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:35:20,872 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 2/89 [00:00<00:05, 16.33it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/89 [00:00<00:09,  9.02it/s]\u001b[A\n",
      "  7%|██▉                                         | 6/89 [00:00<00:09,  8.45it/s]\u001b[A\n",
      "  8%|███▍                                        | 7/89 [00:00<00:09,  8.31it/s]\u001b[A\n",
      "  9%|███▉                                        | 8/89 [00:00<00:10,  8.04it/s]\u001b[A\n",
      " 11%|████▊                                      | 10/89 [00:01<00:09,  8.02it/s]\u001b[A\n",
      " 12%|█████▎                                     | 11/89 [00:01<00:09,  8.11it/s]\u001b[A\n",
      " 13%|█████▊                                     | 12/89 [00:01<00:09,  8.08it/s]\u001b[A\n",
      " 15%|██████▎                                    | 13/89 [00:01<00:09,  7.71it/s]\u001b[A\n",
      " 16%|██████▊                                    | 14/89 [00:01<00:10,  7.47it/s]\u001b[A\n",
      " 17%|███████▏                                   | 15/89 [00:01<00:10,  7.26it/s]\u001b[A\n",
      " 18%|███████▋                                   | 16/89 [00:01<00:09,  7.63it/s]\u001b[A\n",
      " 19%|████████▏                                  | 17/89 [00:02<00:09,  7.54it/s]\u001b[A\n",
      " 20%|████████▋                                  | 18/89 [00:02<00:09,  7.52it/s]\u001b[A\n",
      " 21%|█████████▏                                 | 19/89 [00:02<00:09,  7.23it/s]\u001b[A\n",
      " 22%|█████████▋                                 | 20/89 [00:02<00:09,  7.51it/s]\u001b[A\n",
      " 24%|██████████▏                                | 21/89 [00:02<00:09,  7.29it/s]\u001b[A\n",
      " 25%|██████████▋                                | 22/89 [00:02<00:09,  7.36it/s]\u001b[A\n",
      " 26%|███████████                                | 23/89 [00:02<00:09,  7.31it/s]\u001b[A\n",
      " 27%|███████████▌                               | 24/89 [00:03<00:08,  7.48it/s]\u001b[A\n",
      " 28%|████████████                               | 25/89 [00:03<00:08,  7.50it/s]\u001b[A\n",
      " 29%|████████████▌                              | 26/89 [00:03<00:08,  7.34it/s]\u001b[A\n",
      " 30%|█████████████                              | 27/89 [00:03<00:08,  7.21it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 28/89 [00:03<00:08,  6.99it/s]\u001b[A\n",
      " 33%|██████████████                             | 29/89 [00:03<00:08,  6.96it/s]\u001b[A\n",
      " 34%|██████████████▍                            | 30/89 [00:03<00:08,  7.11it/s]\u001b[A\n",
      " 35%|██████████████▉                            | 31/89 [00:04<00:07,  7.35it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 32/89 [00:04<00:07,  7.53it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 33/89 [00:04<00:07,  7.34it/s]\u001b[A\n",
      " 38%|████████████████▍                          | 34/89 [00:04<00:07,  7.26it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 35/89 [00:04<00:07,  7.27it/s]\u001b[A\n",
      " 40%|█████████████████▍                         | 36/89 [00:04<00:06,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████▉                         | 37/89 [00:04<00:06,  7.73it/s]\u001b[A\n",
      " 43%|██████████████████▎                        | 38/89 [00:04<00:06,  7.45it/s]\u001b[A\n",
      " 44%|██████████████████▊                        | 39/89 [00:05<00:06,  7.40it/s]\u001b[A\n",
      " 45%|███████████████████▎                       | 40/89 [00:05<00:06,  7.56it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 41/89 [00:05<00:06,  7.34it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 42/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 43/89 [00:05<00:06,  6.94it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 44/89 [00:05<00:06,  6.95it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 45/89 [00:05<00:06,  7.04it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 46/89 [00:06<00:06,  6.97it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 47/89 [00:06<00:06,  6.94it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 48/89 [00:06<00:05,  7.09it/s]\u001b[A\n",
      " 55%|███████████████████████▋                   | 49/89 [00:06<00:05,  7.01it/s]\u001b[A\n",
      " 56%|████████████████████████▏                  | 50/89 [00:06<00:05,  7.10it/s]\u001b[A\n",
      " 57%|████████████████████████▋                  | 51/89 [00:06<00:05,  7.51it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 52/89 [00:06<00:05,  7.20it/s]\u001b[A\n",
      " 60%|█████████████████████████▌                 | 53/89 [00:07<00:05,  7.09it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 54/89 [00:07<00:04,  7.16it/s]\u001b[A\n",
      " 62%|██████████████████████████▌                | 55/89 [00:07<00:04,  7.08it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 56/89 [00:07<00:04,  7.34it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 57/89 [00:07<00:04,  7.83it/s]\u001b[A\n",
      " 65%|████████████████████████████               | 58/89 [00:07<00:04,  7.46it/s]\u001b[A\n",
      " 66%|████████████████████████████▌              | 59/89 [00:07<00:03,  7.63it/s]\u001b[A\n",
      " 67%|████████████████████████████▉              | 60/89 [00:08<00:03,  7.60it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 61/89 [00:08<00:03,  7.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 62/89 [00:08<00:03,  7.56it/s]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 63/89 [00:08<00:03,  7.36it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 64/89 [00:08<00:03,  7.35it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 65/89 [00:08<00:03,  7.20it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 66/89 [00:08<00:03,  7.42it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 67/89 [00:08<00:02,  7.75it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 68/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▎         | 69/89 [00:09<00:02,  7.86it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 70/89 [00:09<00:02,  7.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 71/89 [00:09<00:02,  7.30it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 72/89 [00:09<00:02,  7.16it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 73/89 [00:09<00:02,  7.69it/s]\u001b[A\n",
      " 84%|████████████████████████████████████▏      | 75/89 [00:09<00:01,  7.93it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 76/89 [00:10<00:01,  7.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▏     | 77/89 [00:10<00:01,  6.96it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 78/89 [00:10<00:01,  7.11it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 79/89 [00:10<00:01,  6.85it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 80/89 [00:10<00:01,  7.03it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 81/89 [00:10<00:01,  7.04it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 82/89 [00:11<00:00,  7.00it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████   | 83/89 [00:11<00:00,  6.96it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 84/89 [00:11<00:00,  7.11it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████  | 85/89 [00:11<00:00,  7.41it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 86/89 [00:11<00:00,  7.88it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 87/89 [00:11<00:00,  7.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.027661509811878204, 'eval_runtime': 12.031, 'eval_samples_per_second': 175.713, 'eval_steps_per_second': 7.398, 'epoch': 9.82}\n",
      " 98%|████████████████████████████████████▎| 3900/3970 [1:15:04<01:12,  1.03s/it]\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.79it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:3942] 2025-03-17 02:35:32,930 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3900\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:35:32,988 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:35:32,989 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:35:33,902 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:35:33,907 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3900/special_tokens_map.json\n",
      "{'loss': 0.0001, 'grad_norm': 7.15727946953848e-05, 'learning_rate': 6.245090874932858e-08, 'epoch': 9.85}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005066716694273055, 'learning_rate': 4.337144596074927e-08, 'epoch': 9.87}\n",
      "{'loss': 0.0, 'grad_norm': 0.00042872881749644876, 'learning_rate': 2.7759170366886688e-08, 'epoch': 9.9}\n",
      "{'loss': 0.0002, 'grad_norm': 3.908038343070075e-05, 'learning_rate': 1.561516552127662e-08, 'epoch': 9.92}\n",
      "{'loss': 0.0001, 'grad_norm': 0.027244355529546738, 'learning_rate': 6.9402742657875826e-09, 'epoch': 9.95}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003903039323631674, 'learning_rate': 1.735098672123181e-09, 'epoch': 9.97}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00033578183501958847, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "100%|█████████████████████████████████████| 3970/3970 [1:16:17<00:00,  1.05it/s][INFO|trainer.py:3942] 2025-03-17 02:36:46,120 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3970\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:36:46,189 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:36:46,190 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:36:46,982 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3970/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:36:47,017 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-3970/special_tokens_map.json\n",
      "[INFO|trainer.py:2657] 2025-03-17 02:36:49,510 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 4581.4111, 'train_samples_per_second': 41.518, 'train_steps_per_second': 0.867, 'train_loss': 0.006375161553593855, 'epoch': 10.0}\n",
      "100%|█████████████████████████████████████| 3970/3970 [1:16:21<00:00,  1.15s/it]\n",
      "[INFO|trainer.py:3942] 2025-03-17 02:36:49,557 >> Saving model checkpoint to /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/\n",
      "[INFO|configuration_utils.py:697] 2025-03-17 02:36:49,606 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-17 02:36:49,607 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-17 02:36:50,427 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-17 02:36:50,432 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        10.0\n",
      "  total_flos               = 493775091GF\n",
      "  train_loss               =      0.0064\n",
      "  train_runtime            =  1:16:21.41\n",
      "  train_samples_per_second =      41.518\n",
      "  train_steps_per_second   =       0.867\n",
      "Figure saved at: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/training_loss.png\n",
      "Figure saved at: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/training_eval_loss.png\n",
      "[WARNING|2025-03-17 02:36:51] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\n",
      "[INFO|trainer.py:4258] 2025-03-17 02:36:51,747 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-03-17 02:36:51,747 >>   Num examples = 2114\n",
      "[INFO|trainer.py:4263] 2025-03-17 02:36:51,747 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 89/89 [00:11<00:00,  7.44it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_loss               =     0.0275\n",
      "  eval_runtime            = 0:00:12.01\n",
      "  eval_samples_per_second =    175.886\n",
      "  eval_steps_per_second   =      7.405\n",
      "[INFO|modelcard.py:449] 2025-03-17 02:37:03,843 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "! llamafactory-cli train /data2/downloads/LLaMA-Factory/qwen2_lora_sft.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347991e-98f4-4d80-b7d7-90a8be524a2b",
   "metadata": {},
   "source": [
    "## 验证数据集上评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b117369-c7f0-4903-b44d-472af97d83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run evaluate.py\n",
    "testdata_path = '/data2/anti_fraud/dataset/eval0819.jsonl'\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f0eef-37dd-46c5-98fc-8d1da34ee396",
   "metadata": {},
   "source": [
    "分别评估验证数据集上在不同checkpoint上的性能表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9019e1-0f49-41b9-9cb1-0cda54b96fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [02:39<00:00, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1157, fp:8, fn:117, tp:1066\n",
      "precision: 0.9925512104283054, recall: 0.9010989010989011, accuracy: 0.946763202725724\n",
      "CPU times: user 3min 4s, sys: 3.78 s, total: 3min 8s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.0152\n",
    "checkpoint_path_900 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-900'\n",
    "evaluate(model_path, checkpoint_path_900, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7679687-65e3-4185-918b-cfd95169b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [02:39<00:00, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1145, fp:20, fn:22, tp:1161\n",
      "precision: 0.983065198983912, recall: 0.981403212172443, accuracy: 0.9821124361158433\n",
      "CPU times: user 3min 3s, sys: 2.89 s, total: 3min 6s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.0137\n",
    "checkpoint_path_1400 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1400'\n",
    "evaluate(model_path, checkpoint_path_1400, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c88dcc-dafa-495a-9b78-b1f6dcd9adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [02:39<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1162, fp:3, fn:34, tp:1149\n",
      "precision: 0.9973958333333334, recall: 0.9712595097210481, accuracy: 0.9842419080068143\n",
      "CPU times: user 3min 6s, sys: 2.92 s, total: 3min 8s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.020\n",
    "checkpoint_path_1800 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1800'\n",
    "evaluate(model_path, checkpoint_path_1800, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52529bfd-6cd2-4d68-b329-923aa01fd283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2348/2348 [02:39<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1159, fp:6, fn:10, tp:1173\n",
      "precision: 0.9949109414758269, recall: 0.9915469146238377, accuracy: 0.9931856899488927\n",
      "CPU times: user 3min 5s, sys: 3.26 s, total: 3min 8s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.035\n",
    "checkpoint_path_2800 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2800'\n",
    "evaluate(model_path, checkpoint_path_2800, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d6e0b-0863-4a07-869e-35da662956a2",
   "metadata": {},
   "source": [
    "从验证数据集上的评估结果来看，模型的精确率和召回率都有了显著的提升，多卡训练效果显著好于单卡，应该是批量增大，训练更稳定带来的好处。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c115e3d-28b1-426d-adc4-b63f940b7bf3",
   "metadata": {},
   "source": [
    "## 测试数据集上评估\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070510d1-f2f1-4833-9f0d-ca50ecd1d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run evaluate.py\n",
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "model_path = '/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct'\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9242b5-e3a1-4b2c-be9d-5a008ceb5743",
   "metadata": {},
   "source": [
    "分别评估不同checkpoint在测试数据集上的性能表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f0c6c2-4c62-435e-8b06-997a53949a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [02:44<00:00, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1141, fp:26, fn:174, tp:1008\n",
      "precision: 0.9748549323017408, recall: 0.8527918781725888, accuracy: 0.9148573861217539\n",
      "CPU times: user 3min 10s, sys: 2.87 s, total: 3min 13s\n",
      "Wall time: 2min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.0152\n",
    "checkpoint_path_900 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-900'\n",
    "evaluate(model_path, checkpoint_path_900, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e49efdb-4957-486b-bd40-7a0eb34599e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [02:45<00:00, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1104, fp:63, fn:66, tp:1116\n",
      "precision: 0.9465648854961832, recall: 0.9441624365482234, accuracy: 0.9450830140485313\n",
      "CPU times: user 3min 11s, sys: 2.8 s, total: 3min 13s\n",
      "Wall time: 2min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.0137\n",
    "checkpoint_path_1400 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1400'\n",
    "evaluate(model_path, checkpoint_path_1400, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d199cd0-061d-435e-b01e-f80bbc821506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [02:45<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1134, fp:33, fn:109, tp:1073\n",
      "precision: 0.9701627486437613, recall: 0.9077834179357022, accuracy: 0.9395487441464453\n",
      "CPU times: user 3min 11s, sys: 2.93 s, total: 3min 14s\n",
      "Wall time: 2min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.020\n",
    "checkpoint_path_1800 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1800'\n",
    "evaluate(model_path, checkpoint_path_1800, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48f85f3a-0fbc-4431-871a-16082a3315c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [02:45<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1118, fp:49, fn:72, tp:1110\n",
      "precision: 0.9577221742881795, recall: 0.9390862944162437, accuracy: 0.9484887186036611\n",
      "CPU times: user 3min 10s, sys: 3.05 s, total: 3min 13s\n",
      "Wall time: 2min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## eval_loss=0.035\n",
    "checkpoint_path_2800 = '/data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-2800'\n",
    "evaluate(model_path, checkpoint_path_2800, testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a204bb-d76b-4d89-a200-abb76bb2ce26",
   "metadata": {},
   "source": [
    "测试数据集上的评测结果相比验证数据集上的评估结果，性能有明显差距，模型训练中应该是出现了过拟合。\n",
    "从相应的损失和梯度数据上也能看出来，在2885步时训练损失已经为0，梯度也变得非常小（0.00016）。\n",
    "```json\n",
    "{'loss': 0.0, 'grad_norm': 0.0001625923760002479, 'learning_rate': 8.870936304049726e-07, 'epoch': 9.43}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
