{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f3d566-772d-4a7e-bfcb-d4eb79c7b846",
   "metadata": {},
   "source": [
    "## 模型导出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb89b2-ac82-4078-934f-d172b1ac7689",
   "metadata": {},
   "source": [
    "使用LoRA 适配器训练好模型后，每次推理时候都需要分别加载基座模型和 LoRA 适配器，一方面比较繁琐，另一方面也不利于模型部署，因此有必要将基座模型和 LoRA 适配器进行合并，导出成一个模型。\n",
    "\n",
    "LLamaFactory中自带模型合并的功能，只需要从`examples/merge_lora/llama3_lora_sft.yaml`拷贝一份配置根据自己的情况进行修改。修改后的配置文件示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35232e1-1506-4ccd-a7a6-e09e4f84a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Note: DO NOT use quantized model or quantization_bit when merging lora adapters\n",
      "\n",
      "### model\n",
      "model_name_or_path: /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\n",
      "adapter_name_or_path: /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1900\n",
      "template: qwen\n",
      "finetuning_type: lora\n",
      "\n",
      "### export\n",
      "export_dir: /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0\n",
      "export_size: 5\n",
      "export_device: cpu\n",
      "export_legacy_format: false\n"
     ]
    }
   ],
   "source": [
    "!cat /data2/downloads/LLaMA-Factory/merge_qwen2_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b64bc-fd5b-4b2e-9989-4a2f499c9e3e",
   "metadata": {},
   "source": [
    "- export_size: 指定导出的模型文件分片大小，单位为GB, 适用于模型比较大需要分片导出的场景，以便在内存限制的设备上加载。\n",
    "- export_device: 导出模型时使用的设备。可以选择 cpu 或 cuda（即 GPU）。如果有强大的 GPU 可以使用，选择 cuda 可以加快导出速度。\n",
    "- export_legacy_format: 指定是否使用旧格式导出模型。通常情况下，选择 false 以导出使用最新格式的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5517b29-0360-452d-af03-34cf73c2cb5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '。' (U+3002) (2397837049.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    使用`llamafactory-cli`执行export命令导出模型。\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '。' (U+3002)\n"
     ]
    }
   ],
   "source": [
    "使用`llamafactory-cli`执行export命令导出模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd890d7-021e-4f4d-a4c4-a83eab31980e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,767 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:15,768 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2313] 2025-03-16 19:42:16,100 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:697] 2025-03-16 19:42:16,103 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-16 19:42:16,104 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2048] 2025-03-16 19:42:16,106 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2313] 2025-03-16 19:42:16,443 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-03-16 19:42:16] llamafactory.data.template:143 >> Add <|im_end|> to stop words.\n",
      "[INFO|configuration_utils.py:697] 2025-03-16 19:42:16,483 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-03-16 19:42:16,484 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"/data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|2025-03-16 19:42:16] llamafactory.model.patcher:143 >> Using KV cache for faster generation.\n",
      "[INFO|modeling_utils.py:3979] 2025-03-16 19:42:16,532 >> loading weights file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/model.safetensors\n",
      "[INFO|modeling_utils.py:1633] 2025-03-16 19:42:16,544 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1140] 2025-03-16 19:42:16,547 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[WARNING|logging.py:329] 2025-03-16 19:42:16,569 >> Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "[INFO|modeling_utils.py:4970] 2025-03-16 19:42:16,818 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4978] 2025-03-16 19:42:16,818 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1093] 2025-03-16 19:42:16,824 >> loading configuration file /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:1140] 2025-03-16 19:42:16,825 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[INFO|2025-03-16 19:42:16] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-03-16 19:42:33] llamafactory.model.adapter:143 >> Merged 1 adapter(s).\n",
      "[INFO|2025-03-16 19:42:33] llamafactory.model.adapter:143 >> Loaded adapter(s): /data2/anti_fraud/models/Qwen2-1___5B-Instruct_ft_0830_2/checkpoint-1900\n",
      "[INFO|2025-03-16 19:42:33] llamafactory.model.loader:143 >> all params: 1,543,714,304\n",
      "[INFO|2025-03-16 19:42:33] llamafactory.train.tuner:143 >> Convert model dtype to: torch.bfloat16.\n",
      "[INFO|configuration_utils.py:423] 2025-03-16 19:42:33,727 >> Configuration saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/config.json\n",
      "[INFO|configuration_utils.py:909] 2025-03-16 19:42:33,732 >> Configuration saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/generation_config.json\n",
      "[INFO|modeling_utils.py:3040] 2025-03-16 19:43:07,440 >> Model weights saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-03-16 19:43:07,464 >> tokenizer config file saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-03-16 19:43:07,929 >> Special tokens file saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/special_tokens_map.json\n",
      "[INFO|2025-03-16 19:43:08] llamafactory.train.tuner:143 >> Ollama modelfile saved in /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0/Modelfile\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli export /data2/downloads/LLaMA-Factory/merge_qwen2_lora_sft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b05bac-e2da-401d-afe4-1486760380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "查看导出的模型文件，可以看到已经按照我们的配置将模型参数进行了两个分片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb5a8d39-4c40-466c-888a-4ade0c3647b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3030606\n",
      "-rw-r--r-- 1 root root        424 Mar 16 19:43 Modelfile\n",
      "-rw-r--r-- 1 root root         80 Mar 16 19:43 added_tokens.json\n",
      "-rw-r--r-- 1 root root        773 Mar 16 19:42 config.json\n",
      "-rw-r--r-- 1 root root        242 Mar 16 19:42 generation_config.json\n",
      "-rw-r--r-- 1 root root    1671853 Mar 16 19:43 merges.txt\n",
      "-rw-r--r-- 1 root root 3087467144 Mar 16 19:43 model.safetensors\n",
      "-rw-r--r-- 1 root root        367 Mar 16 19:43 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root   11418266 Mar 16 19:43 tokenizer.json\n",
      "-rw-r--r-- 1 root root       1355 Mar 16 19:43 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root    2776833 Mar 16 19:43 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd78084a-1c60-4334-90cf-b4b34b051e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3026332\n",
      "-rw-r--r-- 1 root root      11344 Mar 15 23:23 LICENSE\n",
      "-rw-r--r-- 1 root root       3537 Mar 15 23:23 README.md\n",
      "-rw-r--r-- 1 root root        660 Mar 15 23:23 config.json\n",
      "-rw-r--r-- 1 root root         48 Mar 15 23:23 configuration.json\n",
      "-rw-r--r-- 1 root root        242 Mar 15 23:23 generation_config.json\n",
      "-rw-r--r-- 1 root root    1671839 Mar 15 23:23 merges.txt\n",
      "-rw-r--r-- 1 root root 3087467144 Mar 15 23:27 model.safetensors\n",
      "-rw-r--r-- 1 root root    7028015 Mar 15 23:23 tokenizer.json\n",
      "-rw-r--r-- 1 root root       1287 Mar 15 23:23 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root    2776833 Mar 15 23:23 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data2/anti_fraud/models/modelscope/hub/Qwen/Qwen2-1___5B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479f96c-c9c9-4279-81f1-d28768c4be63",
   "metadata": {},
   "source": [
    "## 测试模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce73ab9b-8921-40f1-8da0-d1a1b810be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run evaluate.py\n",
    "model_path = '/data2/anti_fraud/models/Qwen2-1__5B-Instruct-anti_fraud_1__0'\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5c172b-0cd4-4e56-a80b-94d57bfa3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "progress: 100%|██████████| 2348/2348 [01:21<00:00, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1147, fp:18, fn:202, tp:981\n",
      "precision: 0.9819819819819819, recall: 0.8292476754015216, accuracy: 0.9063032367972743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testdata_path = '/data2/anti_fraud/dataset/eval0819.jsonl'\n",
    "evaluate(model_path, '', testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff8feef-f304-45f5-9ebf-58e80e24c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████| 2349/2349 [01:19<00:00, 29.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn：1153, fp:14, fn:221, tp:961\n",
      "precision: 0.9856410256410256, recall: 0.8130287648054145, accuracy: 0.8999574286930608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testdata_path = '/data2/anti_fraud/dataset/test0819.jsonl'\n",
    "evaluate(model_path, '', testdata_path, device, batch=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abab76d-04a4-4162-b03b-f1412b67d369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a026421e-2734-400e-b241-aba973f6b868",
   "metadata": {},
   "source": [
    "## 模型部署\n",
    "\n",
    "查看配置文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa2ee93-2f13-414b-83d8-e6c28d8f6444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: less: command not found\n"
     ]
    }
   ],
   "source": [
    "!less /data2/downloads/LLaMA-Factory/qwen2_inference.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fe0d5-b16c-4149-b5db-51ee1b35fbfd",
   "metadata": {},
   "source": [
    "通过llamafactory启动推理服务的方式：\n",
    "```\n",
    "llamafactory-cli api /data2/downloads/LLaMA-Factory/qwen2_inference.yaml\n",
    "```\n",
    "为了收集日志及指定环境变量，封装为一个启动脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e7ecb-d56f-40d6-a9fd-43b97b2331e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!less ~/anti_fraud_start.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5549a4-8f71-4e88-8f60-a1aae247aaee",
   "metadata": {},
   "source": [
    "启动服务后，使用openai的api来测试服务功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89561102-f44e-4605-aa82-03a0cb837bca",
   "metadata": {},
   "source": [
    "## 推理测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "153c2a80-8455-4008-b02a-316700062536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 620 ms, sys: 83.5 ms, total: 704 ms\n",
      "Wall time: 2.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是阿里云开发的一种超大规模语言模型，我的名字是通义千问。我可以通过理解并生成人类自然语言与用户进行交互，提供帮助和解答问题。我能够进行多领域的知识学习，涵盖历史、科学、文化、艺术等各个领域，拥有丰富的知识库和算法模型。我还可以进行文本生成、问答、代码生成等多种任务，为用户提供高效、准确、个性化的服务。我不断学习和进步，致力于成为用户的智能助手和知识伙伴。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# api_call_example.py\n",
    "from openai import OpenAI\n",
    "\n",
    "def predict(prompt):\n",
    "    client = OpenAI(api_key=\"0\",base_url=\"http://127.0.0.1:8000/v1\")\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    result = client.chat.completions.create(messages=messages, model=\"Qwen2-1__5B-Instruct\")\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "predict(\"详细介绍下你自己。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15927322-62a4-450d-a613-29174c560048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\/'\n",
      "/tmp/ipykernel_2436/1171486641.py:2: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  return f\"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true\\/false)。\\n{content}\"\n"
     ]
    }
   ],
   "source": [
    "def build_fraud_prompt(content):\n",
    "    return f\"下面是一段对话文本, 请分析对话内容是否有诈骗风险，以json格式输出你的判断结果(is_fraud: true\\/false)。\\n{content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33a1d0e2-ed1a-4c44-84c3-1aa5ef2dcb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.5 ms, sys: 21 μs, total: 52.6 ms\n",
      "Wall time: 199 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": true}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "content = '小明: 我们有专业的团队进行风险管理，可以确保你的投资安全。而且我们会提供实时的投资动态，让你随时掌握投资情况。\\n小红: 那我什么时候能回收投资并获得收益呢？\\n小明: 投资期限为1年，到期后你就可以回收本金和收益。\\n小红: 听起来还不错，我会考虑一下。谢谢你的介绍。\\n小明: 不客气，如果你有任何问题，随时可以问我。希望你能抓住这个机会，获得更多的财富。'\n",
    "predict(build_fraud_prompt(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd62d178-5875-47b9-9244-018b2a1c0b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 ms, sys: 0 ns, total: 48.4 ms\n",
      "Wall time: 207 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"is_fraud\": false}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "content = '发言人3: 然后从不管是分业务板块的一个营收占比和分地区板块的或分地区的一个营收占比来看的话，首先这个屠宰基本上是占了公司总体营收的90%以上的一个比例，但是我们可以看到左下角的这个图，近几年畜禽养殖板块其实更多就来自于生猪养殖板块，它对于整个营收的一个占比它其实有一个明显的提升，而且随着未来公司出栏量的一个增长，包括可能猪价的一个后面有一个周期的一个反转的话，可能未来养殖板块它占总营收的一个比例仍然会有一个快速的一个提升。'\n",
    "predict(build_fraud_prompt(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae2d0d-4552-4019-bd00-5de24ed44bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
